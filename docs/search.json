[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Camilo Martinez",
    "section": "",
    "text": "Business Analytics Master’s Student | Data Enthusiast | Finance Passionate\nI am driven by a passion for learning and a deep curiosity about data. I believe numbers offer the clearest path to understanding reality, which is why I advocate for learning through data-driven insights. Originally from Colombia, I now live in New York, where I am pursuing a Master’s in Business Analytics. My focus lies in leveraging analytics to solve complex problems, particularly within the finance industry. I am excited to continue learning and growing in this field, and I am always looking for new opportunities to apply my skills and knowledge."
  },
  {
    "objectID": "mp02.html",
    "href": "mp02.html",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "",
    "text": "Welcome to an exciting exploration of the film industry! In this project, we dive deep into what makes movies successful, analyzing IMDb ratings, audience engagement, and revenue to create a predictive model that can foresee a film’s potential. We’ve uncovered fascinating trends in how genres evolve over time, providing valuable insights for future productions.\nFinally, we present our proposed remake of the iconic North by Northwest, a thrilling opportunity to bring a timeless classic to life for modern audiences. With its strong foundation and fresh vision, we believe this project holds the key to the next big success in cinema!"
  },
  {
    "objectID": "mp02.html#introduction",
    "href": "mp02.html#introduction",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "",
    "text": "Welcome to an exciting exploration of the film industry! In this project, we dive deep into what makes movies successful, analyzing IMDb ratings, audience engagement, and revenue to create a predictive model that can foresee a film’s potential. We’ve uncovered fascinating trends in how genres evolve over time, providing valuable insights for future productions.\nFinally, we present our proposed remake of the iconic North by Northwest, a thrilling opportunity to bring a timeless classic to life for modern audiences. With its strong foundation and fresh vision, we believe this project holds the key to the next big success in cinema!"
  },
  {
    "objectID": "mp02.html#data-source",
    "href": "mp02.html#data-source",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Data Source",
    "text": "Data Source\nFor this project, we utilize data from the Internet Movie Database (IMDb), a widely recognized source of comprehensive movie information. This data is freely available for non-commercial use, offering a rich foundation for analyzing film success factors and industry trends.\nTo download the IMDb datasets into R and begin your own analysis, you can use the following code:\n\nget_imdb_file &lt;- function(fname){\n    BASE_URL &lt;- \"https://datasets.imdbws.com/\"\n    fname_ext &lt;- paste0(fname, \".tsv.gz\")\n    if(!file.exists(fname_ext)){\n        FILE_URL &lt;- paste0(BASE_URL, fname_ext)\n        download.file(FILE_URL, \n                      destfile = fname_ext)\n    }\n    as.data.frame(readr::read_tsv(fname_ext, lazy=FALSE))\n}\n\nNAME_BASICS &lt;- get_imdb_file(\"name.basics\")\n\nFor readability, we change the name of the following tables:\n\nTITLE_BASICS     &lt;- get_imdb_file(\"title.basics\")\nTITLE_EPISODES   &lt;- get_imdb_file(\"title.episode\")\nTITLE_RATINGS    &lt;- get_imdb_file(\"title.ratings\")\nTITLE_CREW       &lt;- get_imdb_file(\"title.crew\")\nTITLE_PRINCIPALS &lt;- get_imdb_file(\"title.principals\")\n\nDue to the large size of these files, loading them may take some time. To speed up the process, you can cache the code chunk that reads the files, which will prevent reloading them every time you run the code."
  },
  {
    "objectID": "mp02.html#data-sub-sampling",
    "href": "mp02.html#data-sub-sampling",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Data Sub-Sampling",
    "text": "Data Sub-Sampling\nSince the data set contains a vast number of data points, we will narrow it down to ensure smooth analysis. For the NAME_BASICS table, we will focus on individuals with at least two “known for” credits, allowing us to work with a more manageable subset of relevant data.\n\nlibrary(dplyr)\nlibrary(stringr)\n\nNAME_BASICS &lt;- NAME_BASICS |&gt; \n    filter(str_count(knownForTitles, \",\") &gt; 1)\n\nIMDb has a long tail of obscure movies:\n\nlibrary(ggplot2)\nlibrary(scales)\n\nTITLE_RATINGS |&gt;\n    ggplot(aes(x=numVotes)) + \n    geom_histogram(bins=30) +\n    xlab(\"Number of IMDB Ratings\") +\n    ylab(\"Number of Titles\") + \n    ggtitle(\"Majority of IMDB Titles Have Less than 100 Ratings\") + \n    theme_bw() + \n    scale_x_log10(label=scales::comma) + \n    scale_y_continuous(label=scales::comma)\n\n\n\n\n\n\n\n\nAs we can see, the majority of titles have fewer than 100 ratings. Therefore, it would be beneficial to filter out titles with less than 100 ratings to focus on more widely rated films. This becomes even clearer in the following visualization:\n\nTITLE_RATINGS |&gt;\n    pull(numVotes) |&gt;\n    quantile()\n\n     0%     25%     50%     75%    100% \n      5      11      26     100 2954275 \n\n\nBy applying this drop, we significantly reduce the size of our data set:\n\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    filter(numVotes &gt;= 100)\n\nNext, we will join the tables to filter out titles with fewer than 100 ratings. We’ll use the semi_join function to retain only the rows that exist in both tables, ensuring we focus on titles with a higher number of ratings.\n\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_CREW &lt;- TITLE_CREW |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_EPISODES_1 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\nTITLE_EPISODES_2 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(parentTconst == tconst))\n\nTITLE_EPISODES &lt;- bind_rows(TITLE_EPISODES_1,\n                            TITLE_EPISODES_2) |&gt;\n    distinct()\n\nTITLE_PRINCIPALS &lt;- TITLE_PRINCIPALS |&gt;\n    semi_join(TITLE_RATINGS, join_by(tconst == tconst))\n\n\nrm(TITLE_EPISODES_1)\nrm(TITLE_EPISODES_2)"
  },
  {
    "objectID": "mp02.html#taking-a-look-at-the-data",
    "href": "mp02.html#taking-a-look-at-the-data",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Taking a Look at the Data",
    "text": "Taking a Look at the Data\nWe will first inspect the data to determine if any changes to the data types are necessary. In this dataset, most columns are being read as character types. This typically happens when missing values are represented in a non-standard way. For example, in these files, missing values are represented as \\N. Since R does not automatically recognize this as an NA value, it treats them as strings.\nTo address this, we need to:\n\nUse the mutate function to modify the columns.\nApply the as.numeric function to convert columns to the correct data type.\n\nWe can clean the datasets using the following code:\n\nNAME_BASICS &lt;- NAME_BASICS |&gt;\n    mutate_if(is.character, ~na_if(., \"\\\\N\")) |&gt;\n    mutate(birthYear = as.numeric(birthYear),\n           deathYear = as.numeric(deathYear))\n\n\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    mutate_if(is.character, ~na_if(., \"\\\\N\")) |&gt;\n    mutate(\n        startYear = as.numeric(startYear), \n        endYear = as.numeric(endYear),    \n        runtimeMinutes = as.numeric(runtimeMinutes)  \n    )\n\n\nTITLE_EPISODES &lt;- TITLE_EPISODES |&gt;\n    mutate_if(is.character, ~na_if(., \"\\\\N\")) |&gt;\n    mutate(\n        seasonNumber = as.numeric(seasonNumber),\n        episodeNumber = as.numeric(episodeNumber)\n    )\n\n\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    mutate_if(is.character, ~na_if(., \"\\\\N\")) |&gt;\n    mutate(\n        averageRating = as.numeric(averageRating), \n        numVotes = as.numeric(numVotes)  \n    )\n\n\nTITLE_CREW &lt;- TITLE_CREW |&gt;\n    mutate_if(is.character, ~na_if(., \"\\\\N\"))\n\n\nTITLE_PRINCIPALS &lt;- TITLE_PRINCIPALS |&gt;\n    mutate_if(is.character, ~na_if(., \"\\\\N\")) |&gt;\n    mutate(characters = str_replace_all(characters, '\\\\[|\\\\\"|\\\\]', '')) #clean undesired characters\n\nDuring the cleaning process, we transformed string columns into numeric columns and cleaned the character columns in the TITLE_PRINCIPALS table. Additionally, across all tables, we replaced any occurrences of \\N with NA values, allowing us to handle missing data more efficiently. In the TITLE_PRINCIPALS table, we also removed unwanted characters to enhance data quality.\nBy cleaning and preparing the data, we now have a clearer view of the relationships between tables and the variables at our disposal."
  },
  {
    "objectID": "mp02.html#data-analysis",
    "href": "mp02.html#data-analysis",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Data Analysis",
    "text": "Data Analysis\nWith the data now properly cleaned and filtered, we can move forward with our analysis. To begin, we will address the following key questions:\n\nHow many movies are in our dataset?\nHow many TV series?\nHow many TV episodes?\n\nAnswering these questions will help us gain an overview of the data set and set the foundation for deeper insights.\n\n# Install and load the gt package\nif(!require(gt)) {\n  install.packages(\"gt\")\n}\nlibrary(gt)\n\n# Get the count of movies, TV series, and TV episodes\nmovie &lt;- TITLE_BASICS |&gt;\n  filter(titleType == \"movie\") |&gt;\n  nrow()\n\ntvSeries &lt;- TITLE_BASICS |&gt;\n  filter(titleType == \"tvSeries\") |&gt;\n  nrow()\n\ntvEpisode &lt;- TITLE_BASICS |&gt;\n  filter(titleType == \"tvEpisode\") |&gt;\n  nrow()\n\n# Create a summary table and apply gt\nsummary_table &lt;- tibble(\n  Title_Type = c(\"Movies\", \"TV Series\", \"TV Episode\"),\n  Count = c(movie, tvSeries, tvEpisode)\n) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Number of Movies, TV Series, and TV Episodes\"\n  )\nsummary_table\n\n\n\n\n\n\n\nNumber of Movies, TV Series, and TV Episodes\n\n\nTitle_Type\nCount\n\n\n\n\nMovies\n100562\n\n\nTV Series\n20186\n\n\nTV Episode\n103647\n\n\n\n\n\n\n\nWe observed a notable trend in our dataset: the number of movies and TV episodes is quite similar, while TV series have the lowest count among the three categories. This insight is particularly interesting as it may guide future analyses and decision-making in the film industry. Understanding these dynamics can help inform production strategies, audience engagement initiatives, and content development."
  },
  {
    "objectID": "mp02.html#data-exploration-oldest-living-person",
    "href": "mp02.html#data-exploration-oldest-living-person",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Data Exploration: Oldest Living Person",
    "text": "Data Exploration: Oldest Living Person\nTo identify the oldest living person in our dataset, we can focus on the NAME_BASICS table, filtering by individuals who are still alive and sorting by birth year. This will allow us to determine who holds the title of the oldest living person in the film industry.\n\nlibrary(dplyr)\nlibrary(DT)  # Use DT for pagination\n\noldest_person &lt;- NAME_BASICS |&gt;         \n  filter(is.na(deathYear)) |&gt;            # Keep only people with NA in deathYear (still alive)\n  mutate(age = 2024 - birthYear) |&gt;      # Calculate their age in 2024\n  filter(age &gt; 110) |&gt; \n  filter(age &lt; 116)  # Filter for ages below 117 year  # Find the person with the maximum age\n\nsummary_table &lt;- oldest_person |&gt; \n  select(Name = primaryName, \"Year of Birth\" = birthYear, Age = age)\n\ndatatable(summary_table, \n          options = list(pageLength = 5),   # Limit to 5 rows per page\n          caption = 'Oldest Person Alive in this Data Set')\n\n\n\n\n\nInitially, we compiled a list of individuals who were 117 years old based on the dataset. However, after further investigation, we found that none of them were alive. We then narrowed the search to people aged 100 to 116, where we identified 297 individuals still living, aided by external sources such as the Internet. Despite this, finding definitive information about the oldest living person remains a challenge, as much of this data is not readily available."
  },
  {
    "objectID": "mp02.html#identifying-a-perfectly-rated-tv-episode",
    "href": "mp02.html#identifying-a-perfectly-rated-tv-episode",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Identifying a Perfectly Rated TV Episode",
    "text": "Identifying a Perfectly Rated TV Episode\nNext, we aimed to identify a TV episode with a perfect 10/10 IMDb rating and at least 200,000 ratings. By filtering our dataset, we can uncover this exceptional episode and determine the series it belongs to.\n\ngood_ranking &lt;- TITLE_BASICS |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;  # Join to bring in titleType from TITLE_BASICS\n  filter(titleType == \"tvEpisode\") |&gt;        # Now you can filter for TV episodes\n  filter(averageRating == 10 & numVotes &gt; 200000) |&gt;  # Filter for 10/10 rating and &gt;200k votes\n  arrange(desc(numVotes))  # Sort in descending order by number of votes\n\n# Create the summary table\nsummary_table &lt;- good_ranking |&gt;\n  select(Name = primaryTitle, rating = averageRating, \"Number of Votes\" = numVotes ) |&gt; \n  gt() |&gt;                       \n  tab_header(\n    title = \"TV Episode with a Rating of 10/10 and More Than 200,000 Votes\"\n  )\n\nsummary_table\n\n\n\n\n\n\n\nTV Episode with a Rating of 10/10 and More Than 200,000 Votes\n\n\nName\nrating\nNumber of Votes\n\n\n\n\nOzymandias\n10\n230332\n\n\n\n\n\n\n\nOur analysis revealed that the Breaking Bad episode “Ozymandias” has achieved a perfect 10/10 rating with over 229,000 votes on IMDb. This episode stands as a milestone in television history, showcasing the pinnacle of storytelling and character development."
  },
  {
    "objectID": "mp02.html#exploring-mark-hamills-most-known-projects",
    "href": "mp02.html#exploring-mark-hamills-most-known-projects",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Exploring Mark Hamill’s Most Known Projects",
    "text": "Exploring Mark Hamill’s Most Known Projects\nWe will now explore the four projects that actor Mark Hamill is most known for on IMDb. Best recognized for his role as Luke Skywalker and his voice work as The Joker, Hamill’s career spans decades. This exploration will help identify the roles that have shaped his legacy across both film and animation.\n\nmark_hamill &lt;- NAME_BASICS |&gt;\n  filter(primaryName == \"Mark Hamill\") |&gt;\n  select(knownForTitles)\n\ntconsts &lt;- strsplit(mark_hamill$knownForTitles, \",\")[[1]]\n\nmark_hamill_title &lt;- TITLE_BASICS |&gt;\n   filter(tconst %in% tconsts) |&gt;\n   select(\"Title Name\" = primaryTitle, Type = titleType) |&gt;\n   gt() |&gt;\n    tab_header(\n    title = \"The four Projects Mark Hamill Is Best Known For\")\n\n\nmark_hamill_title\n\n\n\n\n\n\n\nThe four Projects Mark Hamill Is Best Known For\n\n\nTitle Name\nType\n\n\n\n\nStar Wars: Episode IV - A New Hope\nmovie\n\n\nStar Wars: Episode V - The Empire Strikes Back\nmovie\n\n\nStar Wars: Episode VI - Return of the Jedi\nmovie\n\n\nStar Wars: Episode VIII - The Last Jedi\nmovie\n\n\n\n\n\n\n\nFrom our analysis, we can see that Mark Hamill’s top four “Most Known For” projects are all from the Star Wars franchise, solidifying his iconic role as Luke Skywalker. These films have defined his career and continue to resonate with audiences across generations."
  },
  {
    "objectID": "mp02.html#next-exploration-highest-rated-tv-series",
    "href": "mp02.html#next-exploration-highest-rated-tv-series",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Next Exploration: Highest Rated TV Series",
    "text": "Next Exploration: Highest Rated TV Series\nBuilding on our analysis, we now turn our attention to identifying the TV series with more than 12 episodes that has the highest average rating. By exploring this, we aim to discover which series has consistently captivated audiences over a longer run.\n\nseries &lt;- TITLE_BASICS |&gt;\n  inner_join(TITLE_EPISODES, by = \"tconst\") |&gt;\n  inner_join(TITLE_RATINGS,by = \"tconst\")\n\nbest_series &lt;- series |&gt;\n  filter(episodeNumber &gt; 12) |&gt;\n  distinct() |&gt;\n  filter(averageRating == max(averageRating, na.rm = TRUE)) |&gt;\n  select(\"Tile Name\" = primaryTitle, \"Average Ratings\" = averageRating) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"The TV Series with the Highest Average Rating and More Than 12 Episodes\"\n  )\n  \nbest_series\n\n\n\n\n\n\n\nThe TV Series with the Highest Average Rating and More Than 12 Episodes\n\n\nTile Name\nAverage Ratings\n\n\n\n\nSeries finale\n10\n\n\nI challenge the Ender Dragon in Minecraft (Ending)\n10\n\n\n37. Bolum\n10\n\n\n38. Bolum\n10\n\n\n39. Bolum\n10\n\n\n40. Bolum\n10\n\n\nGoodbye.\n10\n\n\nIce Hockey: Courtney\n10\n\n\nOzymandias\n10\n\n\n\n\n\n\n\nAs we can see in the results, there are several series with more than 12 episodes that hold a perfect rating of 10. However, there seems to be an issue with the data. The series “Bolum” is listed multiple times, which likely represents individual episodes of the same show, rather than different series. This duplication, indicated by episode numbers (e.g., 37. Bolum, 38. Bolum), points to a mistake in how the data has been recorded."
  },
  {
    "objectID": "mp02.html#investigating-jump-the-shark-in-happy-days",
    "href": "mp02.html#investigating-jump-the-shark-in-happy-days",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Investigating “Jump the Shark” in Happy Days",
    "text": "Investigating “Jump the Shark” in Happy Days\nThe TV series Happy Days (1974-1984) gave us the common idiom “jump the shark.” The phrase refers to a moment in a controversial fifth season episode (aired in 1977) where a lead character literally jumped over a shark on water skis. Over time, this phrase has come to mean the point when a once-great show becomes ridiculous and begins to decline in quality.\nTo investigate this, we now ask: Is it true that episodes from the later seasons of Happy Days have lower average ratings than the early seasons? Let’s explore the data to see if there’s a noticeable drop in ratings as the series progressed.\n\ndata &lt;- TITLE_BASICS |&gt;\n  inner_join(TITLE_EPISODES, join_by(tconst == parentTconst)) |&gt;  # Join episodes with series\n  inner_join(TITLE_RATINGS, by = \"tconst\")  # Join ratings dat\n\nhappy_days &lt;- data |&gt;\n    filter(primaryTitle == \"Happy Days\") |&gt;\n    arrange(seasonNumber) |&gt;\n    select(primaryTitle, \"Season Number\" = seasonNumber, \"Average Rating\" = averageRating, year = endYear) |&gt;\n    distinct() |&gt;\n\n  gt() |&gt;\n  tab_header(\n    title = \"Happy Days Seasons & Ratings per season\"\n  )\n\nhappy_days\n\n\n\n\n\n\n\nHappy Days Seasons & Ratings per season\n\n\nprimaryTitle\nSeason Number\nAverage Rating\nyear\n\n\n\n\nHappy Days\n1\n7.4\n1984\n\n\nHappy Days\n2\n7.4\n1984\n\n\nHappy Days\n3\n7.4\n1984\n\n\nHappy Days\n4\n7.4\n1984\n\n\nHappy Days\n5\n7.4\n1984\n\n\nHappy Days\n6\n7.4\n1984\n\n\nHappy Days\n7\n7.4\n1984\n\n\nHappy Days\n8\n7.4\n1984\n\n\nHappy Days\n9\n7.4\n1984\n\n\nHappy Days\n10\n7.4\n1984\n\n\nHappy Days\n11\n7.4\n1984\n\n\n\n\n\n\n\nThe assumption that the later seasons of Happy Days had lower average ratings is not true. As we can observe, the average rating remained constant at 7.4 across all seasons. This disproves the hypothesis that the 1977 “jump the shark” event had a significant impact on the show’s overall ratings.\nDespite the controversy surrounding that episode, the data shows no evidence of a decline in audience ratings afterward."
  },
  {
    "objectID": "mp02.html#creating-criteria-for-how-successful-a-movie-is",
    "href": "mp02.html#creating-criteria-for-how-successful-a-movie-is",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Creating Criteria for How Successful a Movie Is:",
    "text": "Creating Criteria for How Successful a Movie Is:\nAs we aim to propose a new movie, it is important to understand how successful it might be. While success is often subjective, we are using data from the TITLE_RATING table to measure success, considering average rating as a measure of quality and number of votes as a measure of popularity.\nTraditionally, a movie’s success is also evaluated by the revenue it generates. Therefore, we have selected seven movies with the highest revenue and five movies that lost money, with data sourced from Box Office Mojo."
  },
  {
    "objectID": "mp02.html#movie-revenue-table",
    "href": "mp02.html#movie-revenue-table",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Movie Revenue Table",
    "text": "Movie Revenue Table\n\n\n\n\n\n\n\nSuccessful Movies and Revenue\nUnsuccessful Movies, Money Lost\n\n\n\n\nAvatar ($2.92 billion)\nJohn Carter (-$0.20 billion)\n\n\nAvatar: The Way of Water ($2.32 billion)\nThe Lone Ranger (-$0.19 billion)\n\n\nTitanic ($2.25 billion)\nMars Needs Moms (-$0.15 billion)\n\n\nStar Wars: Episode VII - The Force Awakens ($2.07 billion)\nKing Arthur: Legend of the Sword (-$0.15 billion)\n\n\nSpider-Man: No Way Home ($1.92 billion)\nSinbad: Legend of the Seven Seas (-$0.125 billion)\n\n\nJurassic World ($1.67 billion)\nCutthroat Island (-$0.1 billion)\n\n\nTop Gun: Maverick ($1.49 billion)\nR.I.P.D. (-$0.1 billion)\n\n\n\n\n#first we are filtering the movies we need, selecting the usuful tables, such as originalTitle, averageRating, numVotes\nmovies &lt;- TITLE_BASICS |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  filter(titleType == \"movie\")\n  \nfilter_movies &lt;- movies |&gt;\n  filter((str_detect(str_to_lower(primaryTitle), \"avatar\") & startYear == 2009) |\n          (str_detect(str_to_lower(primaryTitle), \"avatar: the way of water\") & startYear == 2022) |\n          (primaryTitle == \"Titanic\" & startYear == 1997) |\n          (str_detect(str_to_lower(primaryTitle), \"star wars\") & startYear == 2015) |\n          (str_detect(str_to_lower(primaryTitle), \"spider-man: no way home\") & startYear == 2021) |\n          (str_detect(str_to_lower(primaryTitle), \"jurassic world\") & startYear == 2015) |\n          (str_detect(str_to_lower(primaryTitle), \"top gun: maverick\") & startYear == 2022) |\n          (str_detect(str_to_lower(primaryTitle), \"john carter\")) |\n          (str_detect(str_to_lower(primaryTitle), \"the lone ranger\") & startYear == 2013) |\n          (str_detect(str_to_lower(primaryTitle), \"mars needs moms\")) |\n          (str_detect(str_to_lower(primaryTitle), \"king arthur\") & startYear == 2017) |\n          (primaryTitle ==  \"Cutthroat Island\") |\n          (primaryTitle ==  \"R.I.P.D.\") |\n          (str_detect(str_to_lower(primaryTitle), \"legend of the seven seas\")))\nfilter_movies &lt;- filter_movies |&gt;\n  arrange(primaryTitle)\n\n# Assign revenue to the filtered dataframe\nfilter_movies$Revenue &lt;- c(\n  2.92,   # Avatar (successful)\n  2.32,   # Avatar: The Way of Water (successful)\n  -0.10,  # Cutthroat Island (loss)\n  -0.20,  # John Carter (loss)\n  1.67,   # Jurassic World (successful)\n  -0.15,  # King Arthur: Legend of the Sword (loss)\n  -0.15,  # Mars Needs Moms (loss)\n  -0.10,  # R.I.P.D. (loss)\n  -0.125, # Sinbad: Legend of the Seven Seas (loss)\n  1.92,   # Spider-Man: No Way Home (successful)\n  2.07,   # Star Wars: Episode VII - The Force Awakens (successful)\n  -0.19,  # The Lone Ranger (loss)\n  2.25,   # Titanic (successful)\n  1.49    # Top Gun: Maverick (successful)\n)\n\nfilter_movies |&gt;\n  arrange(desc(Revenue)) |&gt;  # Sort by revenue\n  select(\"Original Name\" = primaryTitle, \"Average Rating\" = averageRating, \"Votes\" = numVotes, \"Revenue (Billion)\" = Revenue) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"7 most Sucessful and 7 most Unsuccessful Movies based on revenue (on Billion)\"\n   )\n\n\n\n\n\n\n\n7 most Sucessful and 7 most Unsuccessful Movies based on revenue (on Billion)\n\n\nOriginal Name\nAverage Rating\nVotes\nRevenue (Billion)\n\n\n\n\nAvatar\n7.9\n1406045\n2.920\n\n\nAvatar: The Way of Water\n7.5\n513213\n2.320\n\n\nTitanic\n7.9\n1309446\n2.250\n\n\nStar Wars: Episode VII - The Force Awakens\n7.8\n985881\n2.070\n\n\nSpider-Man: No Way Home\n8.2\n911025\n1.920\n\n\nJurassic World\n6.9\n689617\n1.670\n\n\nTop Gun: Maverick\n8.2\n735945\n1.490\n\n\nCutthroat Island\n5.7\n31185\n-0.100\n\n\nR.I.P.D.\n5.6\n146113\n-0.100\n\n\nSinbad: Legend of the Seven Seas\n6.7\n60614\n-0.125\n\n\nKing Arthur: Legend of the Sword\n6.7\n236363\n-0.150\n\n\nMars Needs Moms\n5.4\n24310\n-0.150\n\n\nThe Lone Ranger\n6.4\n246519\n-0.190\n\n\nJohn Carter\n6.6\n289519\n-0.200\n\n\n\n\n\n\n\nAfter adding the revenue column, we will create a model to serve as a criterion for success. The model is based on the following assumptions:\n\nScale: Our success scale will range from 0 to 10, with 10 representing an extremely successful movie.\nRevenue Mapping: For the positive revenue values (successful movies), we will assign ratings between 9.5 and 10, indicating extreme success. For negative revenue values (unsuccessful movies), we will assign ratings between 4 and 7, we choose this number after multiple iterations.\n\nThis range was chosen because, as observed in our table, even if a movie receives a large number of votes, ratings below 7 tend to correlate with more negative feedback, the opposite of what we expect from a successful movie, regardless of popularity.\n\n# Step 1: Define the max and min values for positive and negative revenues\nmax_positive_revenue &lt;- max(filter_movies$Revenue[filter_movies$Revenue &gt; 0])\nmin_positive_revenue &lt;- min(filter_movies$Revenue[filter_movies$Revenue &gt; 0])\n\nmax_negative_revenue &lt;- max(filter_movies$Revenue[filter_movies$Revenue &lt; 0])  # closest to 0\nmin_negative_revenue &lt;- min(filter_movies$Revenue[filter_movies$Revenue &lt; 0])  # most negative\n\n# Step 2: Apply different formulas based on whether revenue is positive or negative\nfilter_movies$Success_Score &lt;- ifelse(\n  filter_movies$Revenue &gt; 0, \n  9.5 + 0.5 * (filter_movies$Revenue - min_positive_revenue) / (max_positive_revenue - min_positive_revenue),  # Positive revenue: 9.5 to 10 scale\n  4 +  3 * (filter_movies$Revenue - min_negative_revenue) / (max_negative_revenue - min_negative_revenue)  # Negative revenue: 6 to 7 scale\n)\n\nfilter_movies |&gt;\n  arrange(desc(Success_Score)) |&gt; # Sort by revenue\n  select(\"Original Name\" = primaryTitle, \"Average Rating\" = averageRating, \"Votes\" = numVotes, \"Success Score\" = Success_Score ) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"7 most Sucessful and 7 most Unsuccessful Movies based on Success Score (on Billion)\"\n   )\n\n\n\n\n\n\n\n7 most Sucessful and 7 most Unsuccessful Movies based on Success Score (on Billion)\n\n\nOriginal Name\nAverage Rating\nVotes\nSuccess Score\n\n\n\n\nAvatar\n7.9\n1406045\n10.000000\n\n\nAvatar: The Way of Water\n7.5\n513213\n9.790210\n\n\nTitanic\n7.9\n1309446\n9.765734\n\n\nStar Wars: Episode VII - The Force Awakens\n7.8\n985881\n9.702797\n\n\nSpider-Man: No Way Home\n8.2\n911025\n9.650350\n\n\nJurassic World\n6.9\n689617\n9.562937\n\n\nTop Gun: Maverick\n8.2\n735945\n9.500000\n\n\nCutthroat Island\n5.7\n31185\n7.000000\n\n\nR.I.P.D.\n5.6\n146113\n7.000000\n\n\nSinbad: Legend of the Seven Seas\n6.7\n60614\n6.250000\n\n\nKing Arthur: Legend of the Sword\n6.7\n236363\n5.500000\n\n\nMars Needs Moms\n5.4\n24310\n5.500000\n\n\nThe Lone Ranger\n6.4\n246519\n4.300000\n\n\nJohn Carter\n6.6\n289519\n4.000000\n\n\n\n\n\n\n\nBased on the assigned success scores, we will apply a linear regression model to determine the parameters B0, B1, and B2. These parameters will help us create an equation that can be applied to the rest of the dataset, allowing us to predict the success of other movies based on their features.\nThe linear regression model will use the following:\n\nB0: The intercept, representing the baseline success score.\nB1: The coefficient for the average rating, indicating the effect of quality on a movie’s success.\nB2: The coefficient for the number of ratings, reflecting how popularity impacts success.\n\n\n# Fit the linear regression model\nmodel &lt;- lm(Success_Score ~ averageRating + numVotes, data = filter_movies)\n\nsummary(model)\n\n\nCall:\nlm(formula = Success_Score ~ averageRating + numVotes, data = filter_movies)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.7786 -0.5785  0.1934  1.0393  1.8759 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   2.140e+00  4.838e+00   0.442    0.667\naverageRating 5.830e-01  7.967e-01   0.732    0.480\nnumVotes      2.731e-06  1.643e-06   1.662    0.125\n\nResidual standard error: 1.498 on 11 degrees of freedom\nMultiple R-squared:  0.6284,    Adjusted R-squared:  0.5608 \nF-statistic: 9.299 on 2 and 11 DF,  p-value: 0.004322\n\n\nBased on the regression analysis, the final model to predict the success score is represented by the following equation:\n\\[\n\\text{Success Score} = 2.133 + 0.5842 \\times (\\text{Average Rating}) + 2.730 \\times 10^{-6} \\times (\\text{Votes})\n\\]\n\nThe R-squared value is 0.6283, meaning that about 62.83% of the variation in the success score can be explained by the average rating and number of votes.\nThe Adjusted R-squared is 0.5607, slightly lower, accounting for the number of predictors in the model.\nWith a p-value of 0.0043, the overall model is statistically significant.\n\nBased on our analysis, we have determined that the threshold for a movie to be considered successful is an average rating of 7.9 or higher."
  },
  {
    "objectID": "mp02.html#analyzing-a-prestige-actor-leonardo-dicaprio",
    "href": "mp02.html#analyzing-a-prestige-actor-leonardo-dicaprio",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Analyzing a Prestige Actor: Leonardo DiCaprio",
    "text": "Analyzing a Prestige Actor: Leonardo DiCaprio\nNext, we will examine the projects of a prestigious actor, Leonardo DiCaprio, and confirm that many of his films achieve high scores on our success metric. By applying the model to his body of work, we can validate the consistency of his successful film career and analyze the impact of his films based on our criteria.\n\n# Filter the data for Leonardo DiCaprio and Christopher Nolan\nleonardo_dicaprio &lt;- NAME_BASICS |&gt;\n  filter(primaryName == \"Leonardo DiCaprio\") |&gt;\n  select(knownForTitles)\n\nnolan &lt;- NAME_BASICS |&gt;\n  filter(primaryName == \"Christopher Nolan\") |&gt;\n  select(knownForTitles)\n\n# Split the knownForTitles column to get the tconsts\ntconsts_leonardo &lt;- strsplit(leonardo_dicaprio$knownForTitles, \",\")[[1]]\ntconsts_nolan &lt;- strsplit(nolan$knownForTitles, \",\")[[1]]\n\n# Filter the movies based on the tconsts for Leonardo DiCaprio and Christopher Nolan\nleonardo_movies &lt;- movies |&gt;\n  filter(tconst %in% tconsts_leonardo) |&gt;\n  mutate(Person = \"Leonardo DiCaprio\")\n\nnolan_movies &lt;- movies |&gt;\n  filter(tconst %in% tconsts_nolan) |&gt;\n  mutate(Person = \"Christopher Nolan\")\n\nleonardo_nolan_movies &lt;- bind_rows(leonardo_movies, nolan_movies)\n\nleonardo_nolan_movies |&gt;\n  select(\"Original Name\" = primaryTitle, \n         \"Average Rating\" = averageRating, \n         \"Votes\" = numVotes, \n         \"Status\" = SuccessStatus, \n         \"Associated With\" = Person) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Movies Associated with Leonardo DiCaprio and Christopher Nolan\"\n  )\n\n\n\n\n\n\n\nMovies Associated with Leonardo DiCaprio and Christopher Nolan\n\n\nOriginal Name\nAverage Rating\nVotes\nStatus\nAssociated With\n\n\n\n\nTitanic\n7.9\n1309446\nSuccessful\nLeonardo DiCaprio\n\n\nThe Departed\n8.5\n1449409\nSuccessful\nLeonardo DiCaprio\n\n\nThe Wolf of Wall Street\n8.2\n1627553\nSuccessful\nLeonardo DiCaprio\n\n\nInception\n8.8\n2605397\nSuccessful\nLeonardo DiCaprio\n\n\nThe Prestige\n8.5\n1472193\nSuccessful\nChristopher Nolan\n\n\nInterstellar\n8.7\n2179321\nSuccessful\nChristopher Nolan\n\n\nInception\n8.8\n2605397\nSuccessful\nChristopher Nolan\n\n\n\n\n\n\n\nAs we can see, both Leonardo DiCaprio and Christopher Nolan have a significant number of movies that score highly on our success metric. This confirms their prestige and success in the film industry, as their films consistently receive high ratings and are recognized as successful according to our model."
  },
  {
    "objectID": "mp02.html#final-validation-analyzing-bottom-successful-movies",
    "href": "mp02.html#final-validation-analyzing-bottom-successful-movies",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Final Validation: Analyzing Bottom Successful Movies",
    "text": "Final Validation: Analyzing Bottom Successful Movies\nFor our final validation, we will select the bottom 5 successful movies based on our success metric and manually check if they have won any major awards. This will help us assess whether the model accurately reflects not only commercial success but also critical recognition in the film industry.\n\n# Select top 5 movies based on success score\ntop_movies &lt;- movies |&gt;\n  arrange(desc(SuccessNewScore)) |&gt;\n  filter(SuccessStatus == \"Successful\") |&gt;\n  slice_tail(n = 5)\n\nsummarize &lt;-top_movies |&gt;\n  select(\"Original Name\" = primaryTitle, \n         \"Average Rating\" = averageRating, \n         \"Votes\" = numVotes, \n         \"Success Score\" = SuccessNewScore, \n         \"Status\" = SuccessStatus) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Bottom 5 succesful Movies Based on Success Score\"\n  )\nsummarize\n\n\n\n\n\n\n\nBottom 5 succesful Movies Based on Success Score\n\n\nOriginal Name\nAverage Rating\nVotes\nSuccess Score\nStatus\n\n\n\n\nAvatar: The Way of Water\n7.5\n513213\n7.915571\nSuccessful\n\n\nWreck-It Ralph\n7.7\n468223\n7.909589\nSuccessful\n\n\nThe Breakfast Club\n7.8\n446608\n7.909000\nSuccessful\n\n\nIndependence Day\n7.0\n617080\n7.907028\nSuccessful\n\n\nTo Kill a Mockingbird\n8.3\n337554\n7.903382\nSuccessful\n\n\n\n\n\n\n\nFrom the bottom 5 successful movies, we can see that all of them have received good recognition. Notably, 3 out of the 5 have won awards, with one being a nominee, which further confirms the accuracy of our model in predicting the success of a movie based on its average rating and number of votes."
  },
  {
    "objectID": "mp02.html#threshold-for-success",
    "href": "mp02.html#threshold-for-success",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Threshold for Success",
    "text": "Threshold for Success\nWe examined the “Success Score” metric, which combines both IMDb rating and number of votes. This score reflects both the quality and popularity of a movie. Based on our analysis, we determined that the threshold for a movie to be considered successful is an average rating of 7.9 or higher.\nThis threshold was derived from the analysis of the top 7 successful movies and the bottom 7 unsuccessful movies in terms of revenue. The score of 7.9 corresponds to the lowest rating of the most successful movies, specifically Avatar: The Way of Water.\nHowever, this threshold can be adjusted due to the limited number of successful movies. Adjusting the threshold to 7.5 would represent the average rating of successful films, expanding the criteria from 149 successful movies to 542 movies, thus providing a more inclusive measure of success.\n\nlibrary(tidyr)\n\n#changing the threshold to 7.5\nTITLE_RATINGS$SuccessStatus &lt;- ifelse(TITLE_RATINGS$SuccessNewScore &gt; 7.5, \"Successful\", \"Unsuccessful\")\n\nmovies &lt;- TITLE_BASICS |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  filter(titleType == \"movie\")\n\nsuccessful_genre &lt;- movies |&gt;\n  filter(SuccessStatus == \"Successful\") |&gt;\n  mutate(decade = floor(startYear / 10) * 10) |&gt;\n  separate_rows(genres, sep = \",\") |&gt;  # Split genres into individual rows\n  group_by(decade, genres) |&gt;\n  summarise(count = n(), .groups = 'drop')  # Summarise with count\n\nsuccessful_genre_per_decade &lt;- successful_genre |&gt;\n  group_by(decade) |&gt;\n  filter(count == max(count)) \n\nggplot(successful_genre_per_decade, aes(x = decade, y = count, fill = genres)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +  \n  labs(title = \"Most Successful Genres by Decade\",\n       x = \"Decade\",\n       y = \"Number of Movies\",\n       fill = \"Genre\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\") +\n  scale_fill_brewer(palette = \"Set1\") \n\n\n\n\n\n\n\n\nFor each decade, we observe a variety of genres that have achieved success. However, Drama stands out as the most consistently successful genre across all decades. This indicates that drama movies have consistently resonated with audiences and garnered positive reception from critics. While other genres have experienced success in different decades, none have matched the enduring appeal of drama."
  },
  {
    "objectID": "mp02.html#studying-the-evolution-of-genres-over-time",
    "href": "mp02.html#studying-the-evolution-of-genres-over-time",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Studying the Evolution of Genres Over Time",
    "text": "Studying the Evolution of Genres Over Time\nWe aim to explore which genre consistently yields the most “successes” and identify genres that once produced reliable successes but have since fallen out of favor. To accomplish this, we will exclude drama from our analysis and examine the top 2 genres for each decade, allowing us to highlight emerging trends and shifts in audience preferences.\n\nsuccessful_genre_per_decade &lt;- successful_genre |&gt;\n  filter(genres != \"Drama\") |&gt;\n  group_by(decade) |&gt;\n  arrange(decade, desc(count)) |&gt;  # Arrange by decade and descending count\n  slice_head(n = 2)  # Select the top 2 genres per decade\n\nggplot(successful_genre_per_decade, aes(x = decade, y = count, fill = genres)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +  \n  labs(title = \"Most Successful Genres by Decade (Excluding Drama)\",\n       x = \"Decade\",\n       y = \"Number of Movies\",\n       fill = \"Genre\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\") +\n  scale_fill_brewer(palette = \"Set1\") \n\n\n\n\n\n\n\n\nAfter excluding the drama genre, we observe that Action and Adventure have been the most successful genres over time, with Action showing significant growth and Adventure demonstrating more consistency. Other genres, such as Mystery, Crime, and Comedy, have had success in the past but lack the consistency seen in Action and Adventure. Additionally, the growth of the Thriller genre in the last decade is noteworthy; it has emerged as the third most successful genre following Drama and Action."
  },
  {
    "objectID": "mp02.html#movies-production-vs.-success",
    "href": "mp02.html#movies-production-vs.-success",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Movies Production vs. Success",
    "text": "Movies Production vs. Success\nWe aim to analyze the relationship between the number of movies produced and the number of successful movies. Specifically, we want to determine if the number of successful movies has increased over time and whether the ratio of successful movies to total movies has changed. To achieve this, we will calculate the success ratio by decade and genre, focusing on the top 5 genres: Drama, Action, Adventure, Thriller, and Crime.\n\nlibrary(dplyr)\nlibrary(gt)\n\ntop_genres &lt;- c(\"Drama\", \"Action\", \"Adventure\", \"Thriller\", \"Crime\")\n\nratio_successs &lt;- movies |&gt;\n  mutate(decade = floor(startYear / 10) * 10) |&gt;\n  separate_rows(genres, sep = \",\") |&gt;  # Split genres into individual rows if it's a combined column\n  filter(genres %in% top_genres) |&gt;  # Focus only on top 5 genre\n  group_by(decade, genres) |&gt;\n  summarise(\n    total_movies = n(), \n    successful_movies = sum(SuccessStatus == \"Successful\"), \n    .groups = 'drop'\n  ) |&gt;\n  mutate(successful_ratio = round((successful_movies / total_movies)*100, 2))  # Round to 2 decimals\n\nggplot(ratio_successs, aes(x = decade, y = successful_ratio, color = genres)) +\n  geom_line() +\n  geom_point() +\n  labs(title = \"Percentage of Successful Movies to Total Movies by Decade and Genre\",\n       x = \"Decade\",\n       y = \"Success Ratio\",\n       color = \"Genre\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\") +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\nWith this graph, we can observe the varying ratios of success, indicating the percentage of successful movies within each genre. Overall, there is a clear upward trend in the success of movies across all genres. However, Adventure and Action have shown the most significant growth since the 1970s, while Drama has maintained a consistent performance over time. This highlights the evolving landscape of popular genres and their ability to resonate with audiences across different decades.\n\nggplot(ratio_successs, aes(x = decade, y = total_movies, fill = genres)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Total Number of Movies by Decade and Genre\",\n       x = \"Decade\",\n       y = \"Number of Movies\",\n       fill = \"Genre\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\") +\n  scale_fill_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\nFrom these results, we can clearly see that the number of movies created in the Drama genre consistently exceeds that of any other genre by more than double, though the success ratio has increased over time. In contrast, the success ratios for Adventure and Action have shown growth since the 1970s, while the number of movies produced in these genres has remained steady.\nAdditionally, we observe that in the last decade, Thriller has increased both in the number of movies created and its success ratio, indicating a positive trend for this genre. Overall, there is a decline in movie productions, which can be attributed to the rise of streaming services that have transformed the way movies are produced and consumed. This trend is likely to continue as the industry adapts to new technologies and shifting consumer preferences."
  },
  {
    "objectID": "mp02.html#hollywood-project",
    "href": "mp02.html#hollywood-project",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Hollywood Project",
    "text": "Hollywood Project\nThe next step is to create our own movie. To do this, we will first select a genre, two actors, and one director that would be ideal for the film. Here are the criteria we will use:\n\nGenre: Adventure, combined with some Action, as it has proven consistent over time with a high success ratio.\nActors and Director: We will select successful individuals from this genre while incorporating some new actors who have found success in the last decade.\n\n\nmy_genres &lt;- c(\"Action\", \"Adventure\")\n\nmy_movie &lt;-movies |&gt;\n  inner_join(TITLE_PRINCIPALS, by = \"tconst\") |&gt;\n  inner_join(NAME_BASICS, by = \"nconst\")\n\nget_crew &lt;- my_movie |&gt;\n  filter(startYear &gt;= 2008) |&gt;\n  separate_rows(genres, sep = \",\") |&gt;  \n  filter(genres %in% my_genres, SuccessStatus == \"Successful\")\n\ntop_actors &lt;- get_crew |&gt;\n  filter(category == \"actor\" | category == \"actress\") |&gt;\n  group_by(primaryName) |&gt;  \n  summarise(successful_movies = n()) |&gt;  # Count the number of successful movies per actor\n  arrange(desc(successful_movies)) |&gt;  # Sort by most successful movies\n  slice_head(n = 6)  # Select the top 5 actors\n\ntop_directors &lt;- get_crew |&gt;\n  filter(category == \"director\") |&gt;  \n  group_by(primaryName) |&gt;  \n  summarise(successful_movies = n()) |&gt;  \n  arrange(desc(successful_movies))|&gt; \n  slice_head(n = 7)  \n\ntop_actors |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 5 Actors in Successful Action/Adventure Movies After 2010\"\n  )\n\n\n\n\n\n\n\nTop 5 Actors in Successful Action/Adventure Movies After 2010\n\n\nprimaryName\nsuccessful_movies\n\n\n\n\nRobert Downey Jr.\n7\n\n\nChris Evans\n6\n\n\nIrrfan Khan\n5\n\n\nAndrew Garfield\n4\n\n\nChris Pine\n4\n\n\nClark Gregg\n4\n\n\n\n\n\n\ntop_directors |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Most Important Directors in Successful Action/Adventure Movies After 2010\"\n  )\n\n\n\n\n\n\n\nMost Important Directors in Successful Action/Adventure Movies After 2010\n\n\nprimaryName\nsuccessful_movies\n\n\n\n\nDavid Yates\n3\n\n\nZack Snyder\n3\n\n\nChris Sanders\n2\n\n\nChristopher Nolan\n2\n\n\nColin Trevorrow\n2\n\n\nDean DeBlois\n2\n\n\nGuy Ritchie\n2\n\n\n\n\n\n\n\nNow that we have identified the actors with the most success in the Adventure genre, we will select the top 2 actors and the top director based on their success ratios. To accomplish this, we will calculate the ratio of successful movies to total movies for each actor and director.\nFollowing this analysis, we will create a bar plot to visualize both the total number of movies and the number of successful movies for the selected actors and directors. This will help us clearly see who has performed best in this genre and support our decision-making process for the movie project.\n\n#parameters to select the actors and directors with our genre. \nselected_actors &lt;- c(\"Chris Evans\", \"Hugo Weaving\", \"Robert Downey Jr.\", \"Irrfan Khan\", \"Clark Gregg\", \"Henry Cavill\")\nselected_directors &lt;- c(\"David Yates\", \"Zack Snyder\", \"Chris Sanders\", \"Christopher Nolan\", \"Dean DeBlois\", \"Guy Ritchie\", \"J.J. Abrams\")\nmy_genres &lt;- c(\"Action\", \"Adventure\")\n\n\n# Step 2: Filter the data for selected actors and directors\nactor_movies &lt;- my_movie |&gt;\n  separate_rows(genres, sep = \",\") |&gt;  \n  filter(genres %in% my_genres & startYear &gt;= 2008 & primaryName %in% selected_actors)|&gt;\n  group_by(primaryName) |&gt;\n  summarise(total_movies = n())\n\ndirector_movies &lt;- my_movie |&gt;\n  separate_rows(genres, sep = \",\") |&gt;  \n  filter(genres %in% my_genres & startYear &gt;= 2008 & primaryName %in% selected_directors)|&gt;\n  group_by(primaryName) |&gt;\n  summarise(total_movies = n())\n\n# we would calculate the success ratio for each actor. \nactor_data &lt;- actor_movies |&gt;\n  left_join(top_actors, by = \"primaryName\") |&gt;\n  replace_na(list(successful_movies = 0)) |&gt;\n  mutate(success_ratio = successful_movies / total_movies)  # Calculate success ratio\n\n# Reshape data for easier plotting of bars,  this help us to create the plot.\nactor_data_long &lt;- actor_data |&gt;\n  pivot_longer(cols = c(\"total_movies\", \"successful_movies\"), \n               names_to = \"category\", \n               values_to = \"count\")\n\n# Create the bar plot with a line for the success ratio\nggplot() +\n  # Bar plot for total and successful movies\n  geom_bar(data = actor_data_long, aes(x = primaryName, y = count, fill = category), \n           stat = \"identity\", position = \"dodge\") +\n  \n  # Line plot for success ratio (on top of the original unreshaped data)\n  geom_line(data = actor_data, aes(x = primaryName, y = success_ratio * max(actor_data$total_movies), group = 1), \n            color = \"blue\", size = 1, linetype = \"dashed\") +  \n  \n  # Add points for success ratio\n  geom_point(data = actor_data, aes(x = primaryName, y = success_ratio * max(actor_data$total_movies)), \n             color = \"blue\", size = 3) +\n  \n  # Labels and titles\n  labs(title = \"Movies vs Successful Movies (with Success Ratio)\",\n       x = \"Actor\",\n       y = \"Count of Movies\",\n       fill = \"Category\") +\n  \n  # Secondary y-axis for the success ratio\n  scale_y_continuous(sec.axis = sec_axis(~./max(actor_data$total_movies), name = \"Success Ratio\")) +\n  \n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nAfter analyzing the data, we can see that Clark Gregg and Hugo Weaving have a record of success, each with a 100% success ratio in 4 movies after 2008. However, we want to incorporate Chris Evans into our movies because, despite his success ratio being 0.5, he has appeared in 12 movies, which is a good indicator of his popularity and appeal to audiences.\n\n# Prepare the director data (similar process as for actors)\ndirector_data &lt;- director_movies |&gt;\n  left_join(top_directors, by = \"primaryName\") |&gt;\n  replace_na(list(successful_movies = 0)) |&gt;\n  mutate(success_ratio = successful_movies / total_movies)  # Calculate success ratio\n\n# Reshape data for easier plotting of bars\ndirector_data_long &lt;- director_data |&gt;\n  pivot_longer(cols = c(\"total_movies\", \"successful_movies\"), \n               names_to = \"category\", \n               values_to = \"count\")\n\n# Create the bar plot with a line for the success ratio\nggplot() +\n  # Bar plot for total and successful movies\n  geom_bar(data = director_data_long, aes(x = primaryName, y = count, fill = category), \n           stat = \"identity\", position = \"dodge\") +\n  \n  # Line plot for success ratio (on top of the original unreshaped data)\n  geom_line(data = director_data, aes(x = primaryName, y = success_ratio * max(director_data$total_movies), group = 1), \n            color = \"blue\", size = 1, linetype = \"dashed\") +  \n  \n  # Add points for success ratio\n  geom_point(data = director_data, aes(x = primaryName, y = success_ratio * max(director_data$total_movies)), \n             color = \"blue\", size = 3) +\n  \n  # Labels and titles\n  labs(title = \"Movies vs Successful Movies (Directors, After 2010, with Success Ratio)\",\n       x = \"Director\",\n       y = \"Count of Movies\",\n       fill = \"Category\") +\n  \n  # Secondary y-axis for the success ratio\n  scale_y_continuous(sec.axis = sec_axis(~./max(director_data$total_movies), name = \"Success Ratio\")) +\n  \n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\nWarning: Use of `director_data$total_movies` is discouraged.\nℹ Use `total_movies` instead.\nUse of `director_data$total_movies` is discouraged.\nℹ Use `total_movies` instead.\n\n\n\n\n\n\n\n\n\nNow, we will select our director based on the success ratio. In this case, it is an easy pick: we have selected David Yates, who has 3 successful movies out of 5 in the genre we are looking for. Although other directors have more movies, the success ratio is the most important factor in this case."
  },
  {
    "objectID": "mp02.html#movie-creation",
    "href": "mp02.html#movie-creation",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Movie Creation",
    "text": "Movie Creation\nOur movies would be a remake movie, we would look movies that where succesful 25 years ago and we would create a remake of it. We would select 7 movies that have as genre action and adventure, in that way we would be sure that the movie would be successful.\n\nlibrary(knitr)\n\nmy_genres &lt;- c(\"Action\", \"Adventure\")\n\nmy_movie &lt;-movies |&gt;\n  inner_join(TITLE_PRINCIPALS, by = \"tconst\") |&gt;\n  inner_join(NAME_BASICS, by = \"nconst\") |&gt;\n  inner_join(TITLE_CREW, by = \"tconst\")  # Join with crew data\n\n\n\nselection &lt;- my_movie |&gt;\n  separate_rows(genres, sep = \",\") |&gt;\n                \n  filter((startYear &lt; 2000) & (SuccessStatus == \"Successful\") & (genres %in% my_genres)) |&gt;\n  group_by(primaryTitle) |&gt;\n  filter(n_distinct(genres) == 2) |&gt;  # Keep only movies with both Action and Adventure genres\n  arrange(desc(SuccessNewScore)) |&gt;\n  distinct(primaryTitle, .keep_all = TRUE)  |&gt;  #Keep only the first occurrence of each movie, then ungroup\n  ungroup()   \n  \nselection |&gt;\n  select(\"Original Name\" = primaryTitle, \n         \"Average Rating\" = averageRating, \n         \"Votes\" = numVotes,\n         \"Year\" = startYear,\n         \"Success Score\" = SuccessNewScore) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Successful Movies with Action and Adventure Genres Before 2000\"\n  )\n\n\n\n\n\n\n\nSuccessful Movies with Action and Adventure Genres Before 2000\n\n\nOriginal Name\nAverage Rating\nVotes\nYear\nSuccess Score\n\n\n\n\nStar Wars: Episode IV - A New Hope\n8.6\n1475294\n1977\n11.184673\n\n\nStar Wars: Episode V - The Empire Strikes Back\n8.7\n1406428\n1980\n11.055088\n\n\nTerminator 2: Judgment Day\n8.6\n1199025\n1991\n10.430458\n\n\nStar Wars: Episode VI - Return of the Jedi\n8.3\n1140740\n1983\n10.096080\n\n\nRaiders of the Lost Ark\n8.4\n1052079\n1981\n9.912456\n\n\nJurassic Park\n8.2\n1090143\n1993\n9.899530\n\n\nThe Terminator\n8.1\n943192\n1984\n9.439934\n\n\nAliens\n8.4\n788138\n1986\n9.191897\n\n\nIndiana Jones and the Last Crusade\n8.2\n822785\n1989\n9.169643\n\n\nStar Wars: Episode I - The Phantom Menace\n6.5\n874093\n1999\n8.316574\n\n\nPrincess Mononoke\n8.3\n444856\n1997\n8.196317\n\n\nMen in Black\n7.3\n625083\n1997\n8.104137\n\n\nIndiana Jones and the Temple of Doom\n7.5\n542706\n1984\n7.996087\n\n\nThe Fifth Element\n7.6\n516253\n1997\n7.982291\n\n\nPredator\n7.8\n466197\n1987\n7.962478\n\n\nNorth by Northwest\n8.3\n351696\n1959\n7.941990\n\n\nIndependence Day\n7.0\n617080\n1996\n7.907028\n\n\nDie Hard with a Vengeance\n7.6\n413379\n1995\n7.701445\n\n\nMission: Impossible\n7.2\n478390\n1996\n7.645245\n\n\nBatman\n7.5\n412196\n1989\n7.639795\n\n\nThe Mummy\n7.1\n471372\n1999\n7.567666\n\n\nRamayana: The Legend of Prince Rama\n9.2\n15449\n1993\n7.549816\n\n\nThe Iron Giant\n8.1\n234915\n1999\n7.506338"
  },
  {
    "objectID": "mp02.html#movie-selection-north-by-northwest-1959",
    "href": "mp02.html#movie-selection-north-by-northwest-1959",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Movie Selection: North by Northwest (1959)",
    "text": "Movie Selection: North by Northwest (1959)\nBased on the table analysis, we have chosen North by Northwest (1959) for the following key reasons:\n\nThe movie has not been remade: This classic suspense thriller remains untouched, providing a unique opportunity for a fresh adaptation. Modern audiences might appreciate a new take on the original storyline.\nSimplified rights acquisition:\n\nMost of the original actors and director are no longer living, which may simplify the process of securing rights.\nThis could make the adaptation process faster and less complex from a legal standpoint.\n\n\nA remake of this iconic film can resonate well with contemporary audiences, who may find its themes of suspense, intrigue, and mistaken identity just as compelling today as they were in 1959. A new adaptation, with modern cinematic techniques and storytelling, has the potential to breathe new life into this timeless thriller and mistery.\n\n# Extract genres for \"North by Northwest\"\ngenres &lt;- TITLE_BASICS |&gt;\n  filter(primaryTitle == \"North by Northwest\") |&gt;\n  select(genres)\n\n# Select \"North by Northwest\" for the remake and display relevant info\nnorth &lt;- my_movie |&gt;\n  filter(primaryTitle == \"North by Northwest\") |&gt;\n  select(directors,\n         writers,\n         primaryName) |&gt;\n  distinct()  # Ensure no duplicate rows are included\n\n# Display the selected movie info in a nicely formatted table\nnorth |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Selected Movie for Remake: North by Northwest (1959)\"\n  )\n\n\n\n\n\n\n\nSelected Movie for Remake: North by Northwest (1959)\n\n\ndirectors\nwriters\nprimaryName\n\n\n\n\nnm0000033\nnm0499626,nm0222985\nCary Grant\n\n\nnm0000033\nnm0499626,nm0222985\nEva Marie Saint\n\n\nnm0000033\nnm0499626,nm0222985\nJames Mason\n\n\nnm0000033\nnm0499626,nm0222985\nJessie Royce Landis\n\n\nnm0000033\nnm0499626,nm0222985\nLeo G. Carroll\n\n\nnm0000033\nnm0499626,nm0222985\nJosephine Hutchinson\n\n\nnm0000033\nnm0499626,nm0222985\nPhilip Ober\n\n\nnm0000033\nnm0499626,nm0222985\nMartin Landau\n\n\nnm0000033\nnm0499626,nm0222985\nAdam Williams\n\n\nnm0000033\nnm0499626,nm0222985\nEdward Platt\n\n\nnm0000033\nnm0499626,nm0222985\nAlfred Hitchcock\n\n\nnm0000033\nnm0499626,nm0222985\nErnest Lehman\n\n\nnm0000033\nnm0499626,nm0222985\nBernard Herrmann\n\n\nnm0000033\nnm0499626,nm0222985\nRobert Burks\n\n\nnm0000033\nnm0499626,nm0222985\nGeorge Tomasini\n\n\nnm0000033\nnm0499626,nm0222985\nRobert F. Boyle\n\n\n\n\n\n\n\nBased on the Crew group for this movie, the only one alive is Eva Marie Saint which today has 100 years, which would be a good idea to include her in the movie, to give a sense of continuity with the original movie."
  },
  {
    "objectID": "mp02.html#proposal-for-remake-of-north-by-northwest",
    "href": "mp02.html#proposal-for-remake-of-north-by-northwest",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Proposal for Remake of North by Northwest",
    "text": "Proposal for Remake of North by Northwest\nWe propose a modern remake of Alfred Hitchcock’s 1959 classic North by Northwest, a thrilling action-adventure about mistaken identity and espionage. This project capitalizes on the growing popularity of the action, adventure, and thriller genres, all of which have seen strong growth over the past decade.\nChris Evans (success ratio 0.5, 12 films) will play the lead, Roger Thornhill. His global popularity from blockbuster franchises like Captain America guarantees mass appeal, particularly among younger audiences. Hugo Weaving (100% success ratio, 4 films) will play the sophisticated villain, bringing depth and menace, as he has done in The Matrix and The Lord of the Rings. Clark Gregg (100% success ratio, 4 films) will take on a pivotal supporting role, adding gravitas as a shadowy government figure.\nDavid Yates, with a 60% success ratio, is our chosen director. Known for delivering hits like Harry Potter and Fantastic Beasts, his ability to handle large-scale action-adventure films with complex narratives ensures this project will be a success.\nThe consistent rise of the action-adventure genre, paired with the recent resurgence of thrillers, positions North by Northwest perfectly for a remake. Our analysis shows that these genres have seen significant growth, and tapping into this trend with a strong cast and proven director will maximize our movie’s potential.\nWe project the film to gross $600 to $800 million globally, appealing to both classic film fans and modern action audiences."
  },
  {
    "objectID": "mp02.html#conclusion",
    "href": "mp02.html#conclusion",
    "title": "STA/OPR 9750 Mini-Project #02: The Business of Show Business",
    "section": "Conclusion",
    "text": "Conclusion\nThis project has provided valuable insights into the film industry, focusing on the success of movies based on IMDb ratings, number of votes, and revenue. We have developed a model to predict the success of a movie based on these factors, and we have validated the model through various spot checks and analyses. We have also explored the evolution of genres over time, identifying trends and patterns that can inform future movie production. also, the creation of our own movie has been a great experience, and we are confident that our proposed remake of North by Northwest has the potential to be a success ."
  },
  {
    "objectID": "mp03.html",
    "href": "mp03.html",
    "title": "Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "",
    "text": "Date: November 12th, 2024\nAuthor: Juan Camilo Martinez\n\n\n\nIn the United States, the President isn’t chosen directly by popular vote. Instead, the winner is determined through the Electoral College, a system in which each state’s influence is tied to its congressional representation. With the 2024 Presidential election drawing near, it’s timely to ask: Would a different allocation method for electoral votes result in election outcomes that better represent the national popular vote?\nThis project dives into this question, analyzing historical congressional and presidential election data from MIT’s Election Data Science Lab and UCLA Congressional Boundary Files. By exploring electoral vote distributions under different allocation rules, we aim to see how alternate methods might change election results.\n\n\n\n\n\n\nThe U.S. Constitution sets the foundation of the Electoral College, granting each state a number of electors equal to its congressional delegation: the number of House representatives plus two senators. Most states follow a winner-take-all rule, where the state’s popular vote winner claims all electoral votes. However, states like Nebraska and Maine use a district-wide allocation method, awarding votes by individual district results, with two additional votes for the statewide popular winner.\nIn this analysis, we’ll test four allocation strategies to see their potential impact: 1. State-Wide Winner-Take-All 2. District-Wide Winner-Take-All with At-Large Votes 3. State-Wide Proportional 4. National Proportional\n\n\n\n\n\n\n\nWe start by loading the necessary R packages for data manipulation and visualization.\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(stringr)\nlibrary(statebins)\nlibrary(scales)\n**Data Sources and Import\nThe project uses two primary datasets:\nU.S. House Election Data (1976–2022): Details vote counts from congressional races across the 50 states. U.S. Presidential Election Data (1976–2020): Provides state-level vote counts for presidential elections.\nDATA_HOUSE &lt;- read_csv(\"1976-2022-house.csv\") |&gt; filter(!is.na(party))\nDATA_PRESIDENT &lt;- read_csv(\"1976-2020-president.csv\") |&gt;  filter(!is.na(candidate) & !is.na(party_detailed))\nAdditionally, we download congressional boundary files for spatial analysis, covering elections from 1976 to 2012 from UCLA and from 2013 to 2023 from the U.S. Census Bureau.\nus_shapefiles &lt;- function(start = 95, end = 112) {\n  BASE_URL &lt;- \"https://cdmaps.polisci.ucla.edu/shp/districts\"\n  \ncongress_shapefiles_census &lt;- function(start_year = 2013, end_year = 2023) {\n  BASE_URL &lt;- \"https://www2.census.gov/geo/tiger/TIGER\""
  },
  {
    "objectID": "mp03.html#introduction",
    "href": "mp03.html#introduction",
    "title": "# Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Introduction",
    "text": "Introduction\nIn the United States, the President isn’t chosen directly by popular vote. Instead, the winner is determined through the Electoral College, a system in which each state’s influence is tied to its congressional representation. With the 2024 Presidential election drawing near, it’s timely to ask: Would a different allocation method for electoral votes result in election outcomes that better represent the national popular vote?\nThis project dives into this question, analyzing historical congressional and presidential election data from MIT’s Election Data Science Lab and UCLA Congressional Boundary Files. By exploring electoral vote distributions under different allocation rules, we aim to see how alternate methods might change election results."
  },
  {
    "objectID": "mp03.html#background",
    "href": "mp03.html#background",
    "title": "# Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Background",
    "text": "Background\n\nHow the Electoral College Works\nThe U.S. Constitution sets the foundation of the Electoral College, granting each state a number of electors equal to its congressional delegation: the number of House representatives plus two senators. Most states follow a winner-take-all rule, where the state’s popular vote winner claims all electoral votes. However, states like Nebraska and Maine use a district-wide allocation method, awarding votes by individual district results, with two additional votes for the statewide popular winner.\nIn this analysis, we’ll test four allocation strategies to see their potential impact: 1. State-Wide Winner-Take-All 2. District-Wide Winner-Take-All with At-Large Votes 3. State-Wide Proportional 4. National Proportional"
  },
  {
    "objectID": "mp03.html#data-collection",
    "href": "mp03.html#data-collection",
    "title": "# Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Data Collection",
    "text": "Data Collection\n\nSetting Up the Libraries and Data\nWe start by loading the necessary R packages for data manipulation and visualization.\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(stringr)\nlibrary(statebins)\nlibrary(scales)\nlibrary(usmap)\nlibrary(gt)\nlibrary(DT)\nlibrary(gganimate)\nlibrary(maps)\nlibrary(gifski)"
  },
  {
    "objectID": "mp03.html#data-sources-and-import",
    "href": "mp03.html#data-sources-and-import",
    "title": "# Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Data Sources and Import",
    "text": "Data Sources and Import\nThe project uses two primary datasets:\nU.S. House Election Data (1976–2022): Details vote counts from congressional races across the 50 states. U.S. Presidential Election Data (1976–2020): Provides state-level vote counts for presidential elections.\n\nDATA_HOUSE &lt;- read_csv(\"1976-2022-house.csv\") |&gt; filter(!is.na(party))\nDATA_PRESIDENT &lt;- read_csv(\"1976-2020-president.csv\") |&gt;  filter(!is.na(candidate) & !is.na(party_detailed))\n\nAdditionally, we download congressional boundary files for spatial analysis, covering elections from 1976 to 2012 from UCLA and from 2013 to 2023 from the U.S. Census Bureau.\nFirst, we download the UCLA congressional boundary files.\n\ncongress_shapefiles_ucla &lt;- function(start = 95, end = 112) {\n  BASE_URL &lt;- \"https://cdmaps.polisci.ucla.edu/shp/districts\"\n  \n  # Create directory if it doesn't exist\n  target_dir &lt;- \"data/congress_shapefiles\"\n  if (!dir.exists(target_dir)) {\n    dir.create(target_dir, recursive = TRUE)\n  }\n  \n  for (congress in start:end) {\n    congress_str &lt;- sprintf(\"%03d\", congress)\n    file_url &lt;- paste0(BASE_URL, congress_str, \".zip\")\n    dest_file &lt;- file.path(target_dir, paste0(\"congress_\", congress_str, \"_shapefile.zip\"))\n    \n    # Avoid re-downloading\n    if (!file.exists(dest_file)) {\n      tryCatch({\n        download.file(file_url, destfile = dest_file, mode = \"wb\")\n        # Check if the file is downloaded successfully\n        if (file.size(dest_file) &gt; 0) {\n          message(\"Successfully downloaded shapefile for Congress \", congress_str)\n        } else {\n          file.remove(dest_file)\n          message(\"Download failed for Congress \", congress_str, \". File was empty and deleted.\")\n        }\n      }, error = function(e) {\n        message(\"Error downloading for Congress \", congress_str, \": \", e)\n      })\n    } else {\n      message(\"File for Congress \", congress_str, \" already exists. Skipping download.\")\n    }\n  }\n}\n\n#function\ncongress_shapefiles_ucla(93,112)\n\nNow, we download the U.S. Census Bureau congressional boundary files.\n\n# Define function to download, unzip, and read a shapefile\ndownload_and_read_shapefile &lt;- function(year, congress_num) {\n  # Set base URL and target directory\n  base_url &lt;- sprintf(\"https://www2.census.gov/geo/tiger/TIGER%d/CD/\", year)\n  target_dir &lt;- \"data/congress_shapefiles\"\n  \n  # Create directory if it doesn't exist\n  if (!dir.exists(target_dir)) dir.create(target_dir, recursive = TRUE)\n  \n  # Construct filename and paths\n  file_name &lt;- sprintf(\"tl_%d_us_cd%d\", year, congress_num)\n  zip_file &lt;- file.path(target_dir, paste0(file_name, \".zip\"))\n  unzip_dir &lt;- file.path(target_dir, file_name)\n  shapefile_path &lt;- file.path(unzip_dir, paste0(file_name, \".shp\"))\n  \n  # Download the file if it doesn't exist\n  if (!file.exists(zip_file)) {\n    file_url &lt;- paste0(base_url, file_name, \".zip\")\n    tryCatch({\n      download.file(file_url, destfile = zip_file, mode = \"wb\")\n      if (file.size(zip_file) &gt; 0) {\n        message(\"Downloaded: \", file_name, \" for year \", year)\n      } else {\n        file.remove(zip_file)\n        message(\"Download failed for \", file_name, \". Empty file removed.\")\n      }\n    }, error = function(e) {\n      message(\"Error downloading \", file_name, \": \", e$message)\n    })\n  }\n  \n  # Unzip and read the shapefile if it hasn’t been unzipped already\n  if (file.exists(zip_file) && !file.exists(shapefile_path)) {\n    unzip(zipfile = zip_file, exdir = unzip_dir)\n  }\n  \n  # Load the shapefile if it exists\n  if (file.exists(shapefile_path)) {\n    return(read_sf(shapefile_path))\n  } else {\n    message(\"Shapefile not found for \", file_name, \" in year \", year)\n    return(NULL)\n  }\n}\n# Iterate over years and download shapefiles based on Congress sessions\nbase_year &lt;- 2022\nfor (i in 0:10) {\n  year &lt;- base_year - i\n  \n  # Determine Congress number based on the year\n  congress &lt;- if (year &gt;= 2018) 116\n              else if (year &gt;= 2016) 115\n              else if (year &gt;= 2014) 114\n              else if (year == 2013) 113\n              else if (year == 2012) 112\n              else NA\n  \n  if (!is.na(congress)) {\n    district_name &lt;- sprintf(\"tl_%d_us_cd%d\", year, congress)\n    \n    # Download and read shapefile\n    district_data &lt;- download_and_read_shapefile(year, congress)\n    \n    # Assign the data to a unique variable in the global environment\n    if (!is.null(district_data)) {\n      assign(district_name, district_data, envir = .GlobalEnv)\n    }\n  } else {\n    message(\"Congress data not available for year \", year)\n  }\n}\n\n###Initial Exploration of Vote Count Data\nAnalyze Seat Gains and Losses in the U.S. House (1976-2022) This code calculates which states gained or lost the most seats in the House of Representatives between 1976 and 2022.\n\n# Filter House data for relevant years and calculate seat counts\nhouse_seats_over_time &lt;- DATA_HOUSE |&gt;\n  filter(year %in% c(1976, 2022)) |&gt;\n  distinct(year, state, district) |&gt;\n  group_by(year, state) |&gt;\n  summarise(total_seats = n(), .groups = \"drop\")\n\n# Calculate seat changes from 1976 to 2022\nseat_changes &lt;- house_seats_over_time |&gt;\n  pivot_wider(names_from = year, values_from = total_seats, names_prefix = \"year_\") |&gt;\n  mutate(seat_change = year_2022 - year_1976) |&gt;\n  arrange(desc(seat_change))\n\n# Identify top 5 states with highest seat gains and losses\ntop_gained_states &lt;- seat_changes |&gt; slice_max(seat_change, n = 5)\ntop_lost_states &lt;- seat_changes |&gt; slice_min(seat_change, n = 5)\n\n# Plot top gained seats\nplot_seat_gains &lt;- ggplot(top_gained_states, aes(x = reorder(state, seat_change), y = seat_change, fill = seat_change)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(title = \"Top 5 States with Seat Gains (1976-2022)\",\n       x = \"State\",\n       y = \"Number of Seats Gained\") +\n  scale_fill_gradient(low = \"lightblue\", high = \"darkblue\") +\n  theme_minimal()\n\n# Plot top lost seats\nplot_seat_losses &lt;- ggplot(top_lost_states, aes(x = reorder(state, seat_change), y = seat_change, fill = -seat_change)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(title = \"Top 5 States with Seat Losses (1976-2022)\",\n       x = \"State\",\n       y = \"Number of Seats Lost\") +\n  scale_fill_gradient(low = \"lightcoral\", high = \"darkred\") +\n  theme_minimal()\n\n# Display both plots\nlist(plot_seat_gains, plot_seat_losses)\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\nAs we can see in this graph, the states that gained the most seats are Texas, Florida, California, Arizona, and Georgia. On the other hand, the states that lost the most seats are New York, Ohio, Pennsylvania, Illinois, Ohio, and Michigan. The following table explains the population growth between 1976 to 2022 shifts are the main reason for these changes.\n\n\n\nLocation\nGrowth Percentage\n\n\n\n\nArizona\n192.0%\n\n\nFlorida\n161.9%\n\n\nTexas\n145.9%\n\n\nGeorgia\n125.0%\n\n\nCalifornia\n77.3%\n\n\nUSA\n52.8%\n\n\nIllinois\n12.5%\n\n\nPennsylvania\n10.2%\n\n\nNew York\n10.1%\n\n\nOhio\n9.3%\n\n\nMichigan\n8.1%\n\n\n\nWe see clearly that the Usa is in the middle of the list, and the states that lost the most seats are in the bottom of the list.\n\n# Filter for New York State and relevant House races\nny_house_data &lt;- DATA_HOUSE |&gt;\n  filter(state == \"NEW YORK\", office == \"US HOUSE\")\n\n# Calculate total votes (with fusion) and major party votes (without fusion)\nfusion_analysis &lt;- ny_house_data |&gt;\n  mutate(is_major_party = party %in% c(\"DEMOCRAT\", \"REPUBLICAN\")) |&gt;\n  group_by(year, district, candidate) |&gt;\n  summarise(\n    total_votes_all_lines = sum(candidatevotes, na.rm = TRUE),\n    major_party_votes = sum(candidatevotes[is_major_party], na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\n# Determine winners by both fusion and non-fusion scenarios\nwinners_fusion &lt;- fusion_analysis |&gt;\n  group_by(year, district) |&gt;\n  filter(total_votes_all_lines == max(total_votes_all_lines)) |&gt;\n  select(year, district, candidate, total_votes_all_lines) |&gt;\n  rename(fusion_winner = candidate, fusion_votes = total_votes_all_lines)|&gt;\n  ungroup()\n\nwinners_nonfusion &lt;- fusion_analysis |&gt;\n  group_by(year, district) |&gt;\n  filter(major_party_votes == max(major_party_votes)) |&gt;\n  select(year, district, candidate, major_party_votes) |&gt;\n  rename(nonfusion_winner = candidate, nonfusion_votes = major_party_votes) |&gt;\n  ungroup()\n\n# Find elections where fusion changed the winner\nelection_outcomes &lt;- winners_fusion |&gt;\n  inner_join(winners_nonfusion, by = c(\"year\", \"district\")) |&gt;\n  filter(fusion_winner != nonfusion_winner) |&gt;\n  arrange(desc(year))\n  \n\ndatatable(\n  election_outcomes,\n  options = list(\n    pageLength = 10,         # Rows per page\n    autoWidth = TRUE,        # Adjust columns automatically\n    dom = 'tip',             # Only show table, info, and pagination\n    lengthMenu = c(5, 10, 15, 20)  # Options for rows per page\n  ),\n  rownames = FALSE           # Hide row names\n)\n\n\n\n\n\nAs we can see, fusion voting can be a deciding factor in elections. The table demonstrates that fusion voting increases the likelihood of being elected by enabling candidates to gather votes from multiple party lines. This consolidates support in a way that would not be possible without fusion, giving fusion candidates a strategic advantage.\n###Analyzing Presidential vs. Congressional Vote Patterns Across Parties\nThis analysis explores whether presidential candidates tend to run ahead of or behind their congressional counterparts in the same state. Specifically, we’re investigating if Democratic and Republican presidential candidates receive more votes in a given state than all congressional candidates from their party in that same state.\nThe following code will compare these vote counts, identifying instances where presidential candidates either outperformed (“ahead”) or underperformed (“behind”) their co-partisans. This will also help us understand if this trend varies over time, across states, or between parties, providing insights into the relative popularity of presidential candidates within each party.\n\n# Aggregate Democratic and Republican presidential votes by state and year\npresidential_votes &lt;- DATA_PRESIDENT |&gt;\n  filter(office == \"US PRESIDENT\", party_simplified %in% c(\"DEMOCRAT\", \"REPUBLICAN\")) |&gt;\n  group_by(year, state, party_simplified) |&gt;\n  summarise(total_pres_votes = sum(candidatevotes, na.rm = TRUE), .groups = \"drop\")\n\n# Aggregate Democratic and Republican congressional votes by state and year\ncongressional_votes &lt;- DATA_HOUSE |&gt;\n  filter(office == \"US HOUSE\", party %in% c(\"DEMOCRAT\", \"REPUBLICAN\")) |&gt;\n  group_by(year, state, party) |&gt;\n  summarise(total_congress_votes = sum(candidatevotes, na.rm = TRUE), .groups = \"drop\") |&gt;\n  rename(party_simplified = party)\n\n# Merge the presidential and congressional vote data\nvote_comparison &lt;- presidential_votes |&gt;\n  inner_join(congressional_votes, by = c(\"year\", \"state\", \"party_simplified\")) |&gt;\n  mutate(\n    vote_difference = total_pres_votes - total_congress_votes,\n    ran_ahead = ifelse(vote_difference &gt; 0, \"Ahead\", \"Behind\")\n  )\n\n# Additional Visualization: Calculate the average vote difference per year across all states\navg_vote_diff &lt;- vote_comparison |&gt;\n  group_by(year, party_simplified) |&gt;\n  summarise(avg_vote_difference = mean(vote_difference, na.rm = TRUE), .groups = \"drop\")\n\n# Line chart for average vote difference over time\nggplot(avg_vote_diff, aes(x = year, y = avg_vote_difference, color = party_simplified)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 3) +\n  labs(\n    title = \"Average Vote Difference Between Presidential and Congressional Candidates\",\n    subtitle = \"Across All States, by Party (1976 - 2020)\",\n    x = \"Year\",\n    y = \"Average Vote Difference (Presidential - Congressional)\",\n    color = \"Party\"\n  ) +\n  scale_color_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\")) +\n\n  theme_minimal() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\nAs we can see in the image, the average vote difference between presidential and congressional candidates has fluctuated over the years. On this, we can see a major fluctuation in the Republican party, what indicate that the presidential candidate has a major influence on votes than the congressional candidates. For Democrats, the difference is not that big, but still, the presidential candidate has a major influence on votes than the congressional candidates.\n\n# Summary of total instances where presidential candidates ran ahead or behind, grouped by party\nparty_summary_stats &lt;- vote_comparison |&gt;\n  group_by(party_simplified) |&gt;\n  summarise(\n    total_ahead = sum(ran_ahead == \"Ahead\"),\n    total_behind = sum(ran_ahead == \"Behind\"),\n    Difference = total_ahead - total_behind,  # Calculate the variance between ahead and behind\n    .groups = \"drop\"\n  )\n\n# Display the summary table\nparty_summary_stats |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Summary of Presidential Candidates Running Ahead or Behind Congressional Candidates\",\n    subtitle = \"Total Instances by Party (1976-2020)\"\n  ) |&gt;\n  cols_label(\n    party_simplified = \"Party\",\n    total_ahead = \"Total States (Ahead)\",\n    total_behind = \"Total States (Behind)\",\n    Difference = \"Difference (Ahead - Behind)\"\n  )\n\n\n\n\n\n\n\nSummary of Presidential Candidates Running Ahead or Behind Congressional Candidates\n\n\nTotal Instances by Party (1976-2020)\n\n\nParty\nTotal States (Ahead)\nTotal States (Behind)\nDifference (Ahead - Behind)\n\n\n\n\nDEMOCRAT\n318\n274\n44\n\n\nREPUBLICAN\n390\n207\n183\n\n\n\n\n\n\n\nFinally, we can observe the difference between the number of states where the presidential candidate ran ahead or behind their congressional counterparts. The table shows that both Democratic and Republican presidential candidates have run ahead more than behind, however, Republicans have a higher difference between the two categories. This indicates that Republican presidential candidates tend to outperform their congressional counterparts more frequently than Democratic candidates.\n\nImporting and Plotting Shapefile Data\nThe shapefiles we downloaded are provided in zip archives containing several files, but we only need the .shp file from each archive. In this section, we’ll walk through extracting the .shp file, loading it into R, and creating a plot from the data. The main tool we’ll use is the sf package, specifically the read_sf() function, which allows us to read shapefiles directly into R. Below, I’ll demonstrate how this process works.\n\nlibrary(ggplot2)\nlibrary(sf)\n\nif(!file.exists(\"nyc_borough_boundaries.zip\")){\n    download.file(\"https://data.cityofnewyork.us/api/geospatial/tqmj-j8zm?method=export&format=Shapefile\", \n              destfile=\"nyc_borough_boundaries.zip\")\n}\n\n##-\ntd &lt;- tempdir(); \nzip_contents &lt;- unzip(\"nyc_borough_boundaries.zip\", \n                      exdir = td)\n    \nfname_shp &lt;- zip_contents[grepl(\"shp$\", zip_contents)]\nnyc_sf &lt;- read_sf(fname_shp)\n\nWith the following code, we can plot the shapefile data to visualize the boundaries of New York City boroughs.\n\nread_shp_from_zip &lt;- function(zip_file) {\n  files_in_zip &lt;- unzip(zip_file, list = TRUE)\n  \n  shp_file &lt;- files_in_zip$Name[grepl(\"\\\\.shp$\", files_in_zip$Name)]\n  \n  if (length(shp_file) == 1) {\n    unzip(zip_file, files = shp_file, exdir = tempdir())\n    \n    shp_path &lt;- file.path(tempdir(), shp_file)\n    \n    shape_data &lt;- read_sf(shp_path)\n    \n    return(shape_data)\n  } else {\n    message(\"No .shp file found in the provided zip archive.\")\n    return(NULL)\n  }\n}\n\nNow we would plot the shapefile data to visualize the boundaries of New York City boroughs.\n\nggplot(nyc_sf, \n       aes(geometry=geometry)) + \n    geom_sf()\n\n\n\n\n\n\n\n\nAlso we can plot the shapefile data with a fill color to visualize the boundaries of New York City boroughs.\n\nggplot(nyc_sf, \n       aes(geometry=geometry, \n           fill = shape_area)) + \n    geom_sf()\n\n\n\n\n\n\n\n\n\n\nElectoral College Results in 2000\nIn this section, we will create a choropleth map to visualize the results of the 2000 U.S. Presidential Election. The map will display the winning party in each state, highlighting the electoral college winner between George W. Bush and Al Gore.\n\n# Step 1: Prepare Election Data\ncat(\"Step 1: Preparing Election Data\\n\")\n\nStep 1: Preparing Election Data\n\nelection_2000 &lt;- DATA_PRESIDENT |&gt;\n  filter(year == 2000, office == \"US PRESIDENT\") |&gt;\n  group_by(state) |&gt;\n  slice_max(order_by = candidatevotes, n = 1) |&gt;\n  ungroup()\n\ncat(\"Columns in election_2000 after filtering for 2000 election:\\n\")\n\nColumns in election_2000 after filtering for 2000 election:\n\nprint(colnames(election_2000))\n\n [1] \"year\"             \"state\"            \"state_po\"         \"state_fips\"      \n [5] \"state_cen\"        \"state_ic\"         \"office\"           \"candidate\"       \n [9] \"party_detailed\"   \"writein\"          \"candidatevotes\"   \"totalvotes\"      \n[13] \"version\"          \"notes\"            \"party_simplified\"\n\n# Step 2: Assign Winning Party\ncat(\"Step 2: Assigning Winning Party\\n\")\n\nStep 2: Assigning Winning Party\n\nelection_2000 &lt;- election_2000 |&gt;\n  mutate(\n    party_winner = ifelse(party_simplified == \"REPUBLICAN\", \"Republican\", \"Democrat\"),\n    state = tolower(state)\n  )\nprint(head(election_2000))\n\n# A tibble: 6 × 16\n   year state      state_po state_fips state_cen state_ic office       candidate\n  &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;    \n1  2000 alabama    AL                1        63       41 US PRESIDENT BUSH, GE…\n2  2000 alaska     AK                2        94       81 US PRESIDENT BUSH, GE…\n3  2000 arizona    AZ                4        86       61 US PRESIDENT BUSH, GE…\n4  2000 arkansas   AR                5        71       42 US PRESIDENT BUSH, GE…\n5  2000 california CA                6        93       71 US PRESIDENT GORE, AL \n6  2000 colorado   CO                8        84       62 US PRESIDENT BUSH, GE…\n# ℹ 8 more variables: party_detailed &lt;chr&gt;, writein &lt;lgl&gt;,\n#   candidatevotes &lt;dbl&gt;, totalvotes &lt;dbl&gt;, version &lt;dbl&gt;, notes &lt;lgl&gt;,\n#   party_simplified &lt;chr&gt;, party_winner &lt;chr&gt;\n\n# Step 3: Define Electoral College Votes (EC)\ncat(\"Step 3: Defining Electoral College Votes\\n\")\n\nStep 3: Defining Electoral College Votes\n\nec_votes &lt;- data.frame(\n  state_po = c(\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"DC\", \"FL\", \"GA\", \"HI\", \"ID\", \"IL\", \"IN\", \"IA\",\n               \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \"NM\",\n               \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\",\n               \"WV\", \"WI\", \"WY\"),\n  EC = c(9, 3, 8, 6, 54, 8, 8, 3, 3, 25, 13, 4, 4, 22, 12, 7, 6, 8, 9, 4, 10, 12, 18, 10, 7, 11, 3, 5, 4, 4, 15, 5,\n         33, 14, 3, 21, 8, 7, 23, 4, 8, 3, 11, 32, 5, 3, 13, 11, 5, 11, 3)\n)\n\n# Step 4: Merge EC into election data\ncat(\"Step 4: Merging Electoral College Votes into Election Data\\n\")\n\nStep 4: Merging Electoral College Votes into Election Data\n\nelection_2000 &lt;- election_2000 |&gt;\n  left_join(ec_votes, by = \"state_po\")\n\ncat(\"Checking for missing values in EC column:\\n\")\n\nChecking for missing values in EC column:\n\nprint(sum(is.na(election_2000$EC)))\n\n[1] 0\n\n# Step 5: Prepare Map Data\ncat(\"Step 5: Preparing Map Data\\n\")\n\nStep 5: Preparing Map Data\n\nus_map &lt;- map_data(\"state\") |&gt;\n  mutate(region = tolower(region))\n\n# Step 6: Merge election data with map data\ncat(\"Step 6: Merging Election Data with Map Data\\n\")\n\nStep 6: Merging Election Data with Map Data\n\nmap_data_with_results &lt;- us_map |&gt;\n  left_join(election_2000, by = c(\"region\" = \"state\"))\nprint(setdiff(us_map$region, election_2000$state))\n\ncharacter(0)\n\n# Step 7: Calculate State Centers for Labels\ncat(\"Step 7: Calculating State Centers for Labels\\n\")\n\nStep 7: Calculating State Centers for Labels\n\nstate_centers &lt;- map_data_with_results |&gt;\n  group_by(region) |&gt;\n  summarize(\n    long_center = mean(range(long, na.rm = TRUE)),\n    lat_center = mean(range(lat, na.rm = TRUE)),\n    state_po = first(state_po),\n    EC = first(EC)\n  ) |&gt;\n  ungroup()\nprint(head(state_centers))\n\n# A tibble: 6 × 5\n  region      long_center lat_center state_po    EC\n  &lt;chr&gt;             &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n1 alabama           -86.7       32.6 AL           9\n2 arizona          -112.        34.2 AZ           8\n3 arkansas          -92.1       34.8 AR           6\n4 california       -119.        37.3 CA          54\n5 colorado         -106.        39.0 CO           8\n6 connecticut       -72.8       41.5 CT           8\n\n# Step 8: Define Offset Labels for Northeastern States\nnortheast_labels &lt;- data.frame(\n  state_po = c(\"NH\", \"VT\", \"MA\", \"RI\", \"CT\", \"NJ\", \"DE\", \"MD\", \"DC\"),\n  long_offset = c(5, 4, 7, 6, 5, 6, 5, 6, 4),\n  lat_offset = c(2, 1, -1, 0, -2, -1, -1, -1, -2)\n)\n\n# Join offset labels with state centers to add adjusted coordinates\nstate_centers &lt;- state_centers |&gt;\n  left_join(northeast_labels, by = \"state_po\") |&gt;\n  mutate(\n    long_center_adjusted = ifelse(!is.na(long_offset), long_center + long_offset, long_center),\n    lat_center_adjusted = ifelse(!is.na(lat_offset), lat_center + lat_offset, lat_center)\n  )\n\n# Prepare connector line data for northeastern states\nnortheast_connectors &lt;- state_centers |&gt;\n  filter(!is.na(long_offset) & !is.na(lat_offset))\n\n# Step 9: Plot the Map with Insets and Connectors\ncat(\"Step 9: Plotting the Map\\n\")\n\nStep 9: Plotting the Map\n\nggplot(map_data_with_results) +\n  # Mainland US\n  geom_polygon(aes(x = long, y = lat, group = group, fill = party_winner), color = \"white\") +\n  # Alaska inset\n  geom_polygon(data = subset(map_data_with_results, region == \"alaska\"),\n               aes(x = long - 35, y = lat + 10, group = group, fill = party_winner), color = \"white\") +\n  # Hawaii inset\n  geom_polygon(data = subset(map_data_with_results, region == \"hawaii\"),\n               aes(x = long + 50, y = lat - 5, group = group, fill = party_winner), color = \"white\") +\n  # Party color scale\n  scale_fill_manual(\n    values = c(\"Democrat\" = \"blue\", \"Republican\" = \"red\"),\n    name = \"2000 Election Winner\",\n    labels = c(\"Democrat\" = \"Gore\", \"Republican\" = \"Bush\"),\n    na.value = \"grey\"\n  ) +\n  # Labels for each state with offset adjustments for northeastern states\n  geom_text(\n    data = state_centers,\n    aes(x = long_center_adjusted, y = lat_center_adjusted, label = paste(state_po, EC)),\n    color = \"black\",\n    size = 3,\n    fontface = \"bold\"\n  ) +\n  # Connector lines for northeastern states\n  geom_segment(data = northeast_connectors, \n               aes(x = long_center, y = lat_center, xend = long_center_adjusted, yend = lat_center_adjusted), \n               color = \"black\", linetype = \"solid\") +\n  # Map labels and theme\n  labs(\n    title = \"2000 Presidential Election Results by State\",\n    subtitle = \"Bush vs. Gore\",\n    caption = \"Data Source: MIT Election Data Science Lab\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(hjust = 0.5, size = 16),\n    plot.subtitle = element_text(hjust = 0.5, size = 12)\n  )\n\n\n\n\n\n\n\ncat(\"Map plot complete with Alaska, Hawaii insets and connectors for northeastern states.\\n\")\n\nMap plot complete with Alaska, Hawaii insets and connectors for northeastern states.\n\n\nNow we can see a clear picture of how the 2000 U.S. Presidential Election played out across the country. The map shows the winning party in each state, highlighting the electoral college winner between George W. Bush and Al Gore. This visualization provides a snapshot of the election results and the distribution of electoral votes across the United States.\nAdvance Chloropleth Visualization of the 2000 U.S. Presidential Election\nAfter this we want to visualize the results of all the U.S. Presidential Elections from 1976 to 2020. The following code will create a faceted map showing the winning party in each state for each election year, along with the corresponding electoral college votes.\n\n# Step 1: Prepare Election Data (for multiple years)\nelection_data &lt;- DATA_PRESIDENT |&gt;\n  filter(office == \"US PRESIDENT\") |&gt;\n  group_by(year, state) |&gt;\n  slice_max(order_by = candidatevotes, n = 1) |&gt;\n  ungroup() |&gt;\n  mutate(\n    party_winner = ifelse(party_simplified == \"REPUBLICAN\", \"Republican\", \"Democrat\"),\n    state = tolower(state)  # Ensure compatibility with map data\n  )\n\n# Step 2: Prepare Map Data\nus_map &lt;- map_data(\"state\") |&gt;\n  mutate(region = tolower(region))\n\n# Step 3: Merge Election Data with Map Data\nmap_data_with_results &lt;- us_map |&gt;\n  left_join(election_data, by = c(\"region\" = \"state\"))\n\nWarning in left_join(us_map, election_data, by = c(region = \"state\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 1 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n# Step 4: Plot the Animated Map with Explicit Colors\nanimated_map &lt;- ggplot(map_data_with_results) +\n  geom_polygon(aes(x = long, y = lat, group = group, fill = party_winner), color = \"white\") +\n  scale_fill_manual(\n    values = c(\"Democrat\" = \"#0000FF\", \"Republican\" = \"#FF0000\"),  # Explicit blue and red\n    name = \"Election Winner\",\n    na.value = \"grey\"  # Handle unexpected NA values as grey\n  ) +\n  labs(\n    title = \"Presidential Election Results by State Over Time\",\n    subtitle = 'Year: {frame_time}',\n    caption = \"Data Source: MIT Election Data Science Lab\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(hjust = 0.5, size = 16),\n    plot.subtitle = element_text(hjust = 0.5, size = 12)\n  ) +\n  transition_time(year) +   # Add animation over time\n  ease_aes('linear')        # Smooth animation\n\n# Render the animation as before\n#animate(animated_map,nframes = 100,fps = 10,width = 800,height = 600, renderer = gifski_renderer(\"election_animation_high_res.gif\"))\n\nknitr::include_graphics(\"election_animation_high_res.gif\")"
  },
  {
    "objectID": "mp03.html#comparing-the-effects-of-ecv-allocation-rules",
    "href": "mp03.html#comparing-the-effects-of-ecv-allocation-rules",
    "title": "# Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Comparing the Effects of ECV Allocation Rules",
    "text": "Comparing the Effects of ECV Allocation Rules\nNow, we are finishing the exploration of the data, we can compare the effects of different Electoral College Vote (ECV).Go through the historical voting data and assign each state’s ECVs according to various strategies:\nState-Wide Winner-Take-All District-Wide Winner-Take-All + State-Wide “At Large” Votes State-Wide Proportional National Proportional\nFirst, we would join the Electoral College votes to the presidential data previously assigned.\n\n# Join the Electoral College votes to the presidential data\npres_data_filtered &lt;- DATA_PRESIDENT |&gt;\n  filter(party_simplified %in% c(\"DEMOCRAT\", \"REPUBLICAN\")) |&gt;\n  left_join(ec_votes, by = \"state_po\")"
  },
  {
    "objectID": "mp03.html#state-wide-winner-take-all",
    "href": "mp03.html#state-wide-winner-take-all",
    "title": "# Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "State-Wide Winner-Take-All",
    "text": "State-Wide Winner-Take-All\n\n# Group by year and state to get the total votes for each candidate within each state\nstatewide_results &lt;- pres_data_filtered |&gt;\n  group_by(year, state, party_simplified) |&gt;\n  summarize(candidatevotes = sum(candidatevotes), EC = first(EC), .groups = \"drop\")\n\n# Determine the winner in each state and assign all ECVs to that candidate\nstatewide_winners &lt;- statewide_results |&gt;\n  group_by(year, state) |&gt;\n  filter(candidatevotes == max(candidatevotes)) |&gt;\n  ungroup()\n\n# Sum ECVs for each party by year\nstatewide_winners_ecv &lt;- statewide_winners |&gt;\n  group_by(year, party_simplified) |&gt;\n  summarize(ecv_total = sum(EC), .groups = \"drop\")\n\n# Plot ECVs over time for State-Wide Winner-Take-All\nggplot(statewide_winners_ecv, aes(x = year, y = ecv_total, color = party_simplified)) +\n  geom_line(size = 1) +  # Slightly thicker line for better visibility\n  geom_point(size = 2) +  # Small points to highlight each year\n  labs(\n    title = \"Electoral College Votes Over Time (State-Wide Winner-Take-All)\",\n    x = \"Year\",\n    y = \"Total Electoral College Votes (ECV)\",\n    color = \"Party\"\n  ) +\n  scale_color_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\")) +  # Custom party colors\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\"),\n    axis.title = element_text(size = 12),\n    axis.text = element_text(size = 10)\n  )\n\n\n\n\n\n\n\n\nThis fist plot shows the ECVs over time for the State-Wide Winner-Take-All allocation method. We can see how the ECVs are distributed between the Democratic and Republican parties in each election year fluctuating over time. Each time a dot is above the other, it means that the party with the higher line won the election. The trends indicate that the differences between parties have decreased over time."
  },
  {
    "objectID": "mp03.html#district-wide-winner-take-all-state-wide-at-large-votes",
    "href": "mp03.html#district-wide-winner-take-all-state-wide-at-large-votes",
    "title": "# Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "District-Wide Winner-Take-All + State-Wide “At Large” Votes",
    "text": "District-Wide Winner-Take-All + State-Wide “At Large” Votes\n\n# Define the list of presidential election years\npresidential_years &lt;- seq(1976, 2020, by = 4)\n\n# Filter DATA_HOUSE and DATA_PRESIDENT to include only presidential election years\ndistrict_data &lt;- DATA_HOUSE |&gt;\n  filter(year %in% presidential_years)\n\npresident_data &lt;- DATA_PRESIDENT |&gt;\n  filter(year %in% presidential_years)\n\n# Step 1: Determine district-level winners for Democrats and Republicans only, and assign 1 ECV per district\ndistrict_winners &lt;- district_data |&gt;\n  filter(party %in% c(\"DEMOCRAT\", \"REPUBLICAN\")) |&gt;\n  group_by(year, state, state_po, district, party) |&gt;\n  summarize(candidatevotes = sum(candidatevotes), .groups = \"drop\") |&gt;\n  group_by(year, state, state_po, district) |&gt;\n  filter(candidatevotes == max(candidatevotes)) |&gt;\n  ungroup() |&gt;\n  mutate(ECV = 1)  # Each district gets 1 ECV\n\n# Step 2: Calculate statewide winners for \"at-large\" ECVs for Democrats and Republicans only\nstatewide_winners &lt;- president_data |&gt;\n  filter(party_simplified %in% c(\"DEMOCRAT\", \"REPUBLICAN\")) |&gt;\n  group_by(year, state, state_po, party_simplified) |&gt;\n  summarize(candidatevotes = sum(candidatevotes), .groups = \"drop\") |&gt;\n  group_by(year, state, state_po) |&gt;\n  filter(candidatevotes == max(candidatevotes)) |&gt;\n  ungroup() |&gt;\n  mutate(ECV = 2)  # Statewide winner gets 2 at-large ECVs\n\n# Step 3: Combine district and state-wide results, focusing only on Democrat and Republican results\ndistrict_plus_at_large &lt;- bind_rows(\n  district_winners |&gt; rename(party_simplified = party),\n  statewide_winners\n)\n\n# Step 4: Summarize ECV allocation by party and year\necv_allocation &lt;- district_plus_at_large |&gt;\n  group_by(year, party_simplified) |&gt;\n  summarize(total_ecv = sum(ECV), .groups = \"drop\")\n\n# Step 5: Verify total ECVs across all states per year to see how they differ from 538\ntotal_ecv_by_year &lt;- ecv_allocation |&gt;\n  group_by(year) |&gt;\n  summarize(yearly_total_ecv = sum(total_ecv))\n\n# Check for any year where the total ECVs do not equal 538\ntotal_ecv_check &lt;- total_ecv_by_year |&gt;\n  filter(yearly_total_ecv != 538)\n\ngt(total_ecv_check)\n\n\n\n\n\n\n\nyear\nyearly_total_ecv\n\n\n\n\n1976\n537\n\n\n1980\n537\n\n\n1984\n537\n\n\n1988\n537\n\n\n1992\n529\n\n\n1996\n537\n\n\n2000\n537\n\n\n2004\n537\n\n\n2008\n537\n\n\n2012\n537\n\n\n2016\n537\n\n\n\n\n\n\n\nThis this we prove that the total ECVs for each year are around 538, which is the total number of Electoral College votes. This confirms that the allocation method is working correctly and that the ECVs are being distributed as expected.\n\nggplot(ecv_allocation, aes(x = year, y = total_ecv, color = party_simplified)) +\n  geom_line(size = 1) +  # Slightly thicker line for better visibility\n  geom_point(size = 2) +  # Small points to emphasize each data point\n  labs(\n    title = \"Electoral College Votes Over Time (District-Wide + At-Large Allocation)\",\n    x = \"Year\",\n    y = \"Electoral College Votes (ECV)\",\n    color = \"Party\"\n  ) +\n  scale_color_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\")) +  # Custom party colors\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\"),\n    axis.title = element_text(size = 12),\n    axis.text = element_text(size = 10)\n  )\n\n\n\n\n\n\n\n\nThis plot shows the ECVs over time for the District-Wide Winner-Take-All + State-Wide “At Large” Votes allocation method. We can see how the ECVs are distributed between the Democratic and Republican parties in each election year, fluctuating over time.\n#State-Wide Proportional\n\n# Step 1: Calculate vote share for Democrats and Republicans in each state\nstatewide_results &lt;- pres_data_filtered |&gt;\n  group_by(year, state, state_po, party_simplified, EC) |&gt;\n  summarize(candidatevotes = sum(candidatevotes), .groups = \"drop\") |&gt;\n  group_by(year, state, state_po) |&gt;\n  mutate(vote_share = candidatevotes / sum(candidatevotes)) |&gt;\n  ungroup()\n\n# Step 2: Allocate ECVs proportionally based on vote share\nstatewide_results &lt;- statewide_results |&gt;\n  mutate(proportional_ecv = round(vote_share * EC))  # Round to ensure integer ECVs\n\n# Step 3: Adjust ECVs to ensure they match the state's total (handle rounding errors)\n# For each state-year, adjust ECVs if the sum does not match the expected total\nstatewide_adjusted &lt;- statewide_results |&gt;\n  group_by(year, state, state_po) |&gt;\n  mutate(\n    ecv_adjustment = EC - sum(proportional_ecv),  # Calculate difference due to rounding\n    proportional_ecv = proportional_ecv + if_else(\n      row_number() == 1 & ecv_adjustment != 0, ecv_adjustment, 0\n    )  # Adjust the first party’s ECV by the remainder\n  ) |&gt;\n  ungroup()\n\n# Step 4: Summarize ECV allocation by party and year\necv_state_proportion &lt;- statewide_adjusted |&gt;\n  group_by(year, party_simplified) |&gt;\n  summarize(total_ecv = sum(proportional_ecv), .groups = \"drop\")\n\n# Step 5: Plot ECV vs Time for Democrats and Republicans (State-Wide Proportional)\nggplot(ecv_state_proportion, aes(x = year, y = total_ecv, color = party_simplified)) +\n  geom_line(size = 1) +  # Slightly thicker line for clarity\n  geom_point(size = 2) +  # Small points to emphasize each data point\n  labs(\n    title = \"Electoral College Votes Over Time (State-Wide Proportional)\",\n    x = \"Year\",\n    y = \"Electoral College Votes (ECV)\",\n    color = \"Party\"\n  ) +\n  scale_color_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\")) +  # Custom party colors\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\"),\n    axis.title = element_text(size = 12),\n    axis.text = element_text(size = 10)\n  )\n\n\n\n\n\n\n\n\nWe can see a difference between this and the others methods, in this one we can see a clear advantage for the Democratic party, this is because the proportional allocation of ECVs is based on the vote share in each state. This method gives a more accurate representation of the popular vote in each state, which can lead to a more balanced distribution of ECVs between the two major parties."
  },
  {
    "objectID": "mp03.html#national-proportional",
    "href": "mp03.html#national-proportional",
    "title": "# Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "National Proportional",
    "text": "National Proportional\n\n# Step 1: Calculate the total national vote share for Democrats and Republicans\nnational_results &lt;- pres_data_filtered |&gt;\n  group_by(year, party_simplified) |&gt;\n  summarize(total_votes = sum(candidatevotes), .groups = \"drop\") |&gt;\n  group_by(year) |&gt;\n  mutate(national_vote_share = total_votes / sum(total_votes)) |&gt;\n  ungroup()\n\n# Step 2: Allocate ECVs based on national vote share\nnational_results &lt;- national_results |&gt;\n  mutate(proportional_ecv = round(national_vote_share * 538))  # Round to ensure integer ECVs\n\n# Step 3: Adjust ECVs to ensure they sum to 538 (handle rounding discrepancies)\n# Adjust any remainder due to rounding so that the sum equals 538\nnational_adjusted &lt;- national_results |&gt;\n  group_by(year) |&gt;\n  mutate(\n    ecv_adjustment = 538 - sum(proportional_ecv),  # Calculate difference due to rounding\n    proportional_ecv = proportional_ecv + if_else(\n      row_number() == 1 & ecv_adjustment != 0, ecv_adjustment, 0\n    )  # Adjust the first party's ECV by the remainder\n  ) |&gt;\n  ungroup()\n\n# Step 4: Plot ECV vs Time for Democrats and Republicans (National Proportional)\nggplot(national_adjusted, aes(x = year, y = proportional_ecv, color = party_simplified)) +\n  geom_line(size = 1) +  # Slightly thicker line for better visibility\n  geom_point(size = 2) +  # Add small points at each year for clarity\n  labs(\n    title = \"ECV Over Time by National Proportional Allocation\",\n    x = \"Year\",\n    y = \"Electoral College Votes (ECV)\",\n    color = \"Party\"\n  ) +\n  scale_color_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\")) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 14),\n    axis.title = element_text(size = 12),\n    axis.text = element_text(size = 10)\n  )\n\n\n\n\n\n\n\n\nNow we would compared all this methods to see the differences between them.\n\n# Total number of elections\ntotal_elections &lt;- 12\n\n# Calculate Republican win percentages for each method\n\n# State-Wide Winner-Take-All\nstatewide_republican_wins &lt;- statewide_winners_ecv |&gt;\n  group_by(year) |&gt;\n  summarize(winning_party = party_simplified[which.max(ecv_total)]) |&gt;\n  ungroup() |&gt;\n  count(winning_party) |&gt;\n  filter(winning_party == \"REPUBLICAN\") |&gt;\n  pull(n)\nstatewide_republican_percentage &lt;- (statewide_republican_wins / total_elections) * 100\nstatewide_democratic_percentage &lt;- 100 - statewide_republican_percentage\n\n# District-Wide Winner-Take-All + At-Large\ndistrict_republican_wins &lt;- ecv_allocation |&gt;\n  group_by(year) |&gt;\n  summarize(winning_party = party_simplified[which.max(total_ecv)]) |&gt;\n  ungroup() |&gt;\n  count(winning_party) |&gt;\n  filter(winning_party == \"REPUBLICAN\") |&gt;\n  pull(n)\ndistrict_republican_percentage &lt;- (district_republican_wins / total_elections) * 100\ndistrict_democratic_percentage &lt;- 100 - district_republican_percentage\n\n# State-Wide Proportional\nstate_proportional_republican_wins &lt;- ecv_state_proportion |&gt;\n  group_by(year) |&gt;\n  summarize(winning_party = party_simplified[which.max(total_ecv)]) |&gt;\n  ungroup() |&gt;\n  count(winning_party) |&gt;\n  filter(winning_party == \"REPUBLICAN\") |&gt;\n  pull(n)\nstate_proportional_republican_percentage &lt;- (state_proportional_republican_wins / total_elections) * 100\nstate_proportional_democratic_percentage &lt;- 100 - state_proportional_republican_percentage\n\n# National Proportional\nnational_proportional_republican_wins &lt;- national_adjusted |&gt;\n  group_by(year) |&gt;\n  summarize(winning_party = party_simplified[which.max(proportional_ecv)]) |&gt;\n  ungroup() |&gt;\n  count(winning_party) |&gt;\n  filter(winning_party == \"REPUBLICAN\") |&gt;\n  pull(n)\nnational_proportional_republican_percentage &lt;- (national_proportional_republican_wins / total_elections) * 100\nnational_proportional_democratic_percentage &lt;- 100 - national_proportional_republican_percentage\n\n# Create a data frame for pie chart data\npie_data &lt;- data.frame(\n  method = c(\"State-Wide Winner-Take-All\", \"District-Wide + At-Large\", \n             \"State-Wide Proportional\", \"National Proportional\"),\n  party = rep(c(\"REPUBLICAN\", \"DEMOCRAT\"), each = 4),\n  percentage = c(\n    statewide_republican_percentage, statewide_democratic_percentage,\n    district_republican_percentage, district_democratic_percentage,\n    state_proportional_republican_percentage, state_proportional_democratic_percentage,\n    national_proportional_republican_percentage, national_proportional_democratic_percentage\n  )\n)\n\nggplot(pie_data, aes(x = \"\", y = percentage, fill = party)) +\n  geom_bar(width = 1, stat = \"identity\") +\n  coord_polar(\"y\") +\n  facet_wrap(~ method, ncol = 2) +  # Arrange facets in a 2x2 grid\n  labs(\n    title = \"Comparison of Party Wins by ECV Allocation Method\",\n    fill = \"Party\"\n  ) +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\")) +\n  geom_text(aes(label = paste0(round(percentage, 1), \"%\")), \n            position = position_stack(vjust = 0.5), size = 3) +  # Add percentages to each segment\n  theme_minimal() +\n  theme(\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank(),\n    axis.text = element_blank(),\n    panel.grid = element_blank(),\n    plot.title = element_text(size = 14, face = \"bold\"),\n    strip.text = element_text(size = 10, face = \"bold\"),  # Smaller facet labels for better fit\n    legend.position = \"bottom\",  # Move legend to bottom for better layout\n    legend.text = element_text(size = 8)  # Smaller legend text\n  )\n\n\n\n\n\n\n\n\n\n# Total number of elections\ntotal_elections &lt;- 12\n\n# Calculate the percentage of Republican wins for each method\n\n# State-Wide Winner-Take-All\nstatewide_republican_wins &lt;- statewide_winners_ecv |&gt;\n  group_by(year) |&gt;\n  summarize(winning_party = party_simplified[which.max(ecv_total)]) |&gt;\n  ungroup() |&gt;\n  count(winning_party) |&gt;\n  filter(winning_party == \"REPUBLICAN\") |&gt;\n  pull(n)\nstatewide_republican_percentage &lt;- round((statewide_republican_wins / total_elections) * 100,2)\nstatewide_democratic_percentage &lt;- 100 - statewide_republican_percentage\n\n# District-Wide Winner-Take-All + At-Large\ndistrict_republican_wins &lt;- ecv_allocation |&gt;\n  group_by(year) |&gt;\n  summarize(winning_party = party_simplified[which.max(total_ecv)]) |&gt;\n  ungroup() |&gt;\n  count(winning_party) |&gt;\n  filter(winning_party == \"REPUBLICAN\") |&gt;\n  pull(n)\ndistrict_republican_percentage &lt;- round((district_republican_wins / total_elections) * 100,2)\ndistrict_democratic_percentage &lt;- 100 - district_republican_percentage\n\n# State-Wide Proportional\nstate_proportional_republican_wins &lt;- ecv_state_proportion |&gt;\n  group_by(year) |&gt;\n  summarize(winning_party = party_simplified[which.max(total_ecv)]) |&gt;\n  ungroup() |&gt;\n  count(winning_party) |&gt;\n  filter(winning_party == \"REPUBLICAN\") |&gt;\n  pull(n)\nstate_proportional_republican_percentage &lt;- round((state_proportional_republican_wins / total_elections) * 100,2)\nstate_proportional_democratic_percentage &lt;- 100 - state_proportional_republican_percentage\n\n# National Proportional\nnational_proportional_republican_wins &lt;- national_adjusted |&gt;\n  group_by(year) |&gt;\n  summarize(winning_party = party_simplified[which.max(proportional_ecv)]) |&gt;\n  ungroup() |&gt;\n  count(winning_party) |&gt;\n  filter(winning_party == \"REPUBLICAN\") |&gt;\n  pull(n)\nnational_proportional_republican_percentage &lt;- round((national_proportional_republican_wins / total_elections) * 100, 2)\nnational_proportional_democratic_percentage &lt;- 100 - national_proportional_republican_percentage\n\n# Create a data frame to summarize the results\nwin_percentage_table &lt;- data.frame(\n  Party = c(\"REPUBLICAN\", \"DEMOCRAT\"),\n  `State-Wide Winner-Take-All` = c(statewide_republican_percentage, statewide_democratic_percentage),\n  `District-Wide + At-Large` = c(district_republican_percentage, district_democratic_percentage),\n  `State-Wide Proportional` = c(state_proportional_republican_percentage, state_proportional_democratic_percentage),\n  `National Proportional` = c(national_proportional_republican_percentage, national_proportional_democratic_percentage)\n)\n\ngt(win_percentage_table) \n\n\n\n\n\n\n\nParty\nState.Wide.Winner.Take.All\nDistrict.Wide...At.Large\nState.Wide.Proportional\nNational.Proportional\n\n\n\n\nREPUBLICAN\n50\n50\n33.33\n33.33\n\n\nDEMOCRAT\n50\n50\n66.67\n66.67"
  },
  {
    "objectID": "mp03.html#analysis-of-each-scheme",
    "href": "mp03.html#analysis-of-each-scheme",
    "title": "# Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Analysis of Each Scheme",
    "text": "Analysis of Each Scheme\nState-Wide Winner-Take-All: This widely used method awards all ECVs to the state-wide popular vote winner, often ignoring narrower vote margins. Result: Produced a balanced outcome, with each party winning 50% of elections (1976–2020), but often distorts national popular vote representation. District-Wide Winner-Take-All + At-Large: ECVs are awarded by district, with two at-large votes for the state winner. Result: Also produced a 50/50 split, providing a slightly more detailed reflection of local preferences, but still favoring swing districts. State-Wide Proportional: ECVs are split based on each candidate’s vote share within a state, offering a fairer reflection of popular support. Result: Democrats won 66.7% of elections, indicating a tilt toward populous urban centers. National Proportional: Allocates ECVs based on the national popular vote percentage. Result: Similar to State-Wide Proportional, with Democrats winning 66.7% of elections, showing a national popular vote bias."
  },
  {
    "objectID": "mp03.html#conclusion-the-fairest-scheme",
    "href": "mp03.html#conclusion-the-fairest-scheme",
    "title": "# Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Conclusion: The Fairest Scheme",
    "text": "Conclusion: The Fairest Scheme\nState-Wide Proportional is arguably the fairest, as it represents the actual vote distribution within each state. However, it significantly shifts outcomes, favoring Democrats due to higher urban population density. For instance, in a year like 2000, where Republicans narrowly won in the actual ECV count, a proportional method could have swung the outcome.\nOverall, State-Wide Proportional most accurately reflects voter preferences but tilts outcomes toward the party with broad, urban support.\nas we can see,"
  }
]